<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Welcome to NeuroDiME’s documentation! &mdash; NeuroDiME: A Software Library on Neural-based Estimation of Divergences and Metrics 0.0.1 documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=19f00094" />

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="_static/jquery.js?v=5d32c60e"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="_static/documentation_options.js?v=d45e8c67"></script>
        <script src="_static/doctools.js?v=9a2dae69"></script>
        <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="models" href="modules.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="#" class="icon icon-home">
            NeuroDiME: A Software Library on Neural-based Estimation of Divergences and Metrics
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="modules.html">models</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="#">NeuroDiME: A Software Library on Neural-based Estimation of Divergences and Metrics</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="#" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Welcome to NeuroDiME’s documentation!</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/index.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="welcome-to-neurodime-s-documentation">
<h1>Welcome to NeuroDiME’s documentation!<a class="headerlink" href="#welcome-to-neurodime-s-documentation" title="Link to this heading"></a></h1>
<div class="toctree-wrapper compound">
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="modules.html">models</a><ul>
<li class="toctree-l2"><a class="reference internal" href="Divergences_jax.html">Divergences_jax module</a></li>
<li class="toctree-l2"><a class="reference internal" href="Divergences_tf.html">Divergences_tf module</a></li>
<li class="toctree-l2"><a class="reference internal" href="Divergences_torch.html">Divergences_torch module</a></li>
<li class="toctree-l2"><a class="reference internal" href="GAN_CIFAR10_jax.html">GAN_CIFAR10_jax module</a></li>
<li class="toctree-l2"><a class="reference internal" href="GAN_CIFAR10_tf.html">GAN_CIFAR10_tf module</a></li>
<li class="toctree-l2"><a class="reference internal" href="GAN_CIFAR10_torch.html">GAN_CIFAR10_torch module</a></li>
<li class="toctree-l2"><a class="reference internal" href="GAN_MNIST_jax.html">GAN_MNIST_jax module</a></li>
<li class="toctree-l2"><a class="reference internal" href="GAN_MNIST_tf.html">GAN_MNIST_tf module</a></li>
<li class="toctree-l2"><a class="reference internal" href="GAN_MNIST_torch.html">GAN_MNIST_torch module</a></li>
<li class="toctree-l2"><a class="reference internal" href="GAN_jax.html">GAN_jax module</a></li>
<li class="toctree-l2"><a class="reference internal" href="GAN_tf.html">GAN_tf module</a></li>
<li class="toctree-l2"><a class="reference internal" href="GAN_torch.html">GAN_torch module</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_jax.html">model_jax module</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_tf.html">model_tf module</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_torch.html">model_torch module</a></li>
</ul>
</li>
</ul>
</div>
<dl class="py class" id="module-Divergences_jax">
<dt class="sig sig-object py" id="Divergences_jax.DataLoader">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">Divergences_jax.</span></span><span class="sig-name descname"><span class="pre">DataLoader</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shuffle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_jax.html#DataLoader"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_jax.DataLoader" title="Link to this definition"></a></dt>
<dd><p>DataLoader class for loading and batching data during training.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="Divergences_jax.Discriminator_Penalty">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">Divergences_jax.</span></span><span class="sig-name descname"><span class="pre">Discriminator_Penalty</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">penalty_weight</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_jax.html#Discriminator_Penalty"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_jax.Discriminator_Penalty" title="Link to this definition"></a></dt>
<dd><p>Base class for implementing penalties on the discriminator during training.
Enables the implementation of discriminator constraints to regularize the divergence objective.</p>
<dl class="py method">
<dt class="sig sig-object py" id="Divergences_jax.Discriminator_Penalty.evaluate">
<span class="sig-name descname"><span class="pre">evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">discriminator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_stats</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">key</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout_rng</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_jax.html#Discriminator_Penalty.evaluate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_jax.Discriminator_Penalty.evaluate" title="Link to this definition"></a></dt>
<dd><p>Evaluates the penalty term. Should be overridden by subclasses.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>discriminator</strong> – Discriminator model.</p></li>
<li><p><strong>x</strong> – Samples from distribution P.</p></li>
<li><p><strong>y</strong> – Samples from distribution Q.</p></li>
<li><p><strong>params</strong> – Discriminator parameters.</p></li>
<li><p><strong>batch_stats</strong> – Additional statistics for the batch.</p></li>
<li><p><strong>key</strong> – Random key for JAX RNG.</p></li>
<li><p><strong>labels</strong> – Optional input labels.</p></li>
<li><p><strong>dropout_rng</strong> – Optional dropout key for stochasticity.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>None. (Subclasses should implement specific penalty evaluations.)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_jax.Discriminator_Penalty.get_penalty_weight">
<span class="sig-name descname"><span class="pre">get_penalty_weight</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_jax.html#Discriminator_Penalty.get_penalty_weight"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_jax.Discriminator_Penalty.get_penalty_weight" title="Link to this definition"></a></dt>
<dd><p>Returns the weight of the penalty.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Penalty weight.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_jax.Discriminator_Penalty.set_penalty_weight">
<span class="sig-name descname"><span class="pre">set_penalty_weight</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">weight</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_jax.html#Discriminator_Penalty.set_penalty_weight"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_jax.Discriminator_Penalty.set_penalty_weight" title="Link to this definition"></a></dt>
<dd><p>Sets the weight of the penalty.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>weight</strong> – New penalty weight.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="Divergences_jax.Divergence">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">Divergences_jax.</span></span><span class="sig-name descname"><span class="pre">Divergence</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">discriminator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">disc_optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">discriminator_penalty</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_jax.html#Divergence"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_jax.Divergence" title="Link to this definition"></a></dt>
<dd><p>Base class for Divergence measures D(P||Q) between random variables x~P, y~Q.
This parent class defines common parameters and functions for different divergence measures.</p>
<dl class="py method">
<dt class="sig sig-object py" id="Divergences_jax.Divergence.discriminate">
<span class="sig-name descname"><span class="pre">discriminate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vars</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout_rng</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_jax.html#Divergence.discriminate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_jax.Divergence.discriminate" title="Link to this definition"></a></dt>
<dd><p>Discriminates between samples from x~P and y~Q using the discriminator model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Input data to be discriminated.</p></li>
<li><p><strong>params</strong> – Parameters of the discriminator model.</p></li>
<li><p><strong>vars</strong> – Additional variables such as batch statistics.</p></li>
<li><p><strong>labels</strong> – Optional labels for the input data.</p></li>
<li><p><strong>dropout_rng</strong> – Optional dropout key for stochasticity in dropout layers.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Tuple of the discriminator output and optional updated batch statistics.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_jax.Divergence.discriminator_loss">
<span class="sig-name descname"><span class="pre">discriminator_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vars</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout_rng</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_jax.html#Divergence.discriminator_loss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_jax.Divergence.discriminator_loss" title="Link to this definition"></a></dt>
<dd><p>Computes the loss for the discriminator model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Samples from P.</p></li>
<li><p><strong>y</strong> – Samples from Q.</p></li>
<li><p><strong>params</strong> – Discriminator parameters.</p></li>
<li><p><strong>vars</strong> – Additional discriminator variables.</p></li>
<li><p><strong>labels</strong> – Optional input labels.</p></li>
<li><p><strong>dropout_rng</strong> – Optional dropout key for stochasticity.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Tuple of discriminator loss and updated variables.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_jax.Divergence.estimate">
<span class="sig-name descname"><span class="pre">estimate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vars</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout_rng</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_jax.html#Divergence.estimate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_jax.Divergence.estimate" title="Link to this definition"></a></dt>
<dd><p>Estimates the divergence between P and Q.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Samples from P.</p></li>
<li><p><strong>y</strong> – Samples from Q.</p></li>
<li><p><strong>params</strong> – Discriminator parameters.</p></li>
<li><p><strong>vars</strong> – Additional discriminator variables.</p></li>
<li><p><strong>labels</strong> – Optional input labels.</p></li>
<li><p><strong>dropout_rng</strong> – Optional dropout key for stochasticity.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Tuple of estimated divergence and updated variables.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_jax.Divergence.eval_var_formula">
<span class="sig-name descname"><span class="pre">eval_var_formula</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vars</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout_rng</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_jax.html#Divergence.eval_var_formula"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_jax.Divergence.eval_var_formula" title="Link to this definition"></a></dt>
<dd><p>Placeholder method for evaluating the variational formula of a specific divergence.
Should be overridden by subclasses.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Samples from P.</p></li>
<li><p><strong>y</strong> – Samples from Q.</p></li>
<li><p><strong>params</strong> – Discriminator parameters.</p></li>
<li><p><strong>vars</strong> – Additional discriminator variables.</p></li>
<li><p><strong>labels</strong> – Optional input labels.</p></li>
<li><p><strong>dropout_rng</strong> – Optional dropout key for stochasticity.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>None.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_jax.Divergence.gen_train_step">
<span class="sig-name descname"><span class="pre">gen_train_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">gen_state</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">disc_state</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">disc_vars</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gen_vars</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">key</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">z</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout_rng</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_jax.html#Divergence.gen_train_step"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_jax.Divergence.gen_train_step" title="Link to this definition"></a></dt>
<dd><p>Performs a single training step for the generator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>gen_state</strong> – Generator optimizer state.</p></li>
<li><p><strong>disc_state</strong> – Discriminator optimizer state.</p></li>
<li><p><strong>disc_vars</strong> – Discriminator variables.</p></li>
<li><p><strong>gen_vars</strong> – Generator variables.</p></li>
<li><p><strong>key</strong> – Random key for JAX RNG.</p></li>
<li><p><strong>z</strong> – Latent input to the generator.</p></li>
<li><p><strong>labels</strong> – Optional input labels.</p></li>
<li><p><strong>dropout_rng</strong> – Optional dropout key for stochasticity.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Updated generator state and generator loss.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_jax.Divergence.generator_loss">
<span class="sig-name descname"><span class="pre">generator_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vars</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout_rng</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_jax.html#Divergence.generator_loss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_jax.Divergence.generator_loss" title="Link to this definition"></a></dt>
<dd><p>Computes the loss for the generator model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Generated samples.</p></li>
<li><p><strong>params</strong> – Discriminator parameters.</p></li>
<li><p><strong>vars</strong> – Additional discriminator variables.</p></li>
<li><p><strong>labels</strong> – Optional input labels.</p></li>
<li><p><strong>dropout_rng</strong> – Optional dropout key for stochasticity.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Tuple of generator loss and updated variables.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_jax.Divergence.get_batch_size">
<span class="sig-name descname"><span class="pre">get_batch_size</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_jax.html#Divergence.get_batch_size"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_jax.Divergence.get_batch_size" title="Link to this definition"></a></dt>
<dd><p>Returns the batch size.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_jax.Divergence.get_discriminator">
<span class="sig-name descname"><span class="pre">get_discriminator</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_jax.html#Divergence.get_discriminator"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_jax.Divergence.get_discriminator" title="Link to this definition"></a></dt>
<dd><p>Returns the discriminator model.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_jax.Divergence.get_learning_rate">
<span class="sig-name descname"><span class="pre">get_learning_rate</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_jax.html#Divergence.get_learning_rate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_jax.Divergence.get_learning_rate" title="Link to this definition"></a></dt>
<dd><p>Returns the learning rate.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_jax.Divergence.get_no_epochs">
<span class="sig-name descname"><span class="pre">get_no_epochs</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_jax.html#Divergence.get_no_epochs"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_jax.Divergence.get_no_epochs" title="Link to this definition"></a></dt>
<dd><p>Returns the number of training epochs.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_jax.Divergence.set_batch_size">
<span class="sig-name descname"><span class="pre">set_batch_size</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_jax.html#Divergence.set_batch_size"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_jax.Divergence.set_batch_size" title="Link to this definition"></a></dt>
<dd><p>Sets the batch size.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>batch_size</strong> – New batch size.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_jax.Divergence.set_discriminator">
<span class="sig-name descname"><span class="pre">set_discriminator</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">discriminator</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_jax.html#Divergence.set_discriminator"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_jax.Divergence.set_discriminator" title="Link to this definition"></a></dt>
<dd><p>Sets a new discriminator model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>discriminator</strong> – New discriminator model.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_jax.Divergence.set_learning_rate">
<span class="sig-name descname"><span class="pre">set_learning_rate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">lr</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_jax.html#Divergence.set_learning_rate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_jax.Divergence.set_learning_rate" title="Link to this definition"></a></dt>
<dd><p>Sets the learning rate.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>lr</strong> – New learning rate.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_jax.Divergence.set_no_epochs">
<span class="sig-name descname"><span class="pre">set_no_epochs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">epochs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_jax.html#Divergence.set_no_epochs"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_jax.Divergence.set_no_epochs" title="Link to this definition"></a></dt>
<dd><p>Sets the number of training epochs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>epochs</strong> – New number of epochs.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_jax.Divergence.train">
<span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_P</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_Q</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">state</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vars</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_estimates</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout_rng</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_jax.html#Divergence.train"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_jax.Divergence.train" title="Link to this definition"></a></dt>
<dd><p>Trains the model for a given number of epochs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data_P</strong> – Data samples from distribution P.</p></li>
<li><p><strong>data_Q</strong> – Data samples from distribution Q.</p></li>
<li><p><strong>state</strong> – Discriminator optimizer state.</p></li>
<li><p><strong>vars</strong> – Discriminator variables.</p></li>
<li><p><strong>save_estimates</strong> – Whether to save divergence estimates.</p></li>
<li><p><strong>labels</strong> – Optional input labels.</p></li>
<li><p><strong>dropout_rng</strong> – Optional dropout key for stochasticity.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Tuple of estimated divergences and losses for each epoch.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_jax.Divergence.train_step">
<span class="sig-name descname"><span class="pre">train_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">state</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vars</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">key</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout_rng</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_jax.html#Divergence.train_step"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_jax.Divergence.train_step" title="Link to this definition"></a></dt>
<dd><p>Performs a single training step for the discriminator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Samples from P.</p></li>
<li><p><strong>y</strong> – Samples from Q.</p></li>
<li><p><strong>state</strong> – Optimizer state.</p></li>
<li><p><strong>vars</strong> – Additional discriminator variables.</p></li>
<li><p><strong>key</strong> – Random key for JAX RNG.</p></li>
<li><p><strong>labels</strong> – Optional input labels.</p></li>
<li><p><strong>dropout_rng</strong> – Optional dropout key for stochasticity.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Updated state and loss value for the current step.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="Divergences_jax.Gradient_Penalty_1Sided">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">Divergences_jax.</span></span><span class="sig-name descname"><span class="pre">Gradient_Penalty_1Sided</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">penalty_weight</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Lip_const</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_jax.html#Gradient_Penalty_1Sided"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_jax.Gradient_Penalty_1Sided" title="Link to this definition"></a></dt>
<dd><p>One-sided gradient penalty to enforce a constraint: Lipschitz constant &lt;= Lip_const.</p>
<dl class="py method">
<dt class="sig sig-object py" id="Divergences_jax.Gradient_Penalty_1Sided.evaluate">
<span class="sig-name descname"><span class="pre">evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">discriminator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_stats</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">key</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout_rng</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_jax.html#Gradient_Penalty_1Sided.evaluate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_jax.Gradient_Penalty_1Sided.evaluate" title="Link to this definition"></a></dt>
<dd><p>Computes the one-sided gradient penalty to enforce the Lipschitz constant constraint.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>discriminator</strong> – Discriminator model.</p></li>
<li><p><strong>x</strong> – Samples from distribution P.</p></li>
<li><p><strong>y</strong> – Samples from distribution Q.</p></li>
<li><p><strong>params</strong> – Discriminator parameters.</p></li>
<li><p><strong>batch_stats</strong> – Additional statistics for the batch.</p></li>
<li><p><strong>key</strong> – Random key for JAX RNG.</p></li>
<li><p><strong>labels</strong> – Optional input labels.</p></li>
<li><p><strong>dropout_rng</strong> – Optional dropout key for stochasticity.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>One-sided gradient penalty value.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_jax.Gradient_Penalty_1Sided.get_Lip_constant">
<span class="sig-name descname"><span class="pre">get_Lip_constant</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_jax.html#Gradient_Penalty_1Sided.get_Lip_constant"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_jax.Gradient_Penalty_1Sided.get_Lip_constant" title="Link to this definition"></a></dt>
<dd><p>Returns the target Lipschitz constant.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Lipschitz constant.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_jax.Gradient_Penalty_1Sided.set_Lip_constant">
<span class="sig-name descname"><span class="pre">set_Lip_constant</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">L</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_jax.html#Gradient_Penalty_1Sided.set_Lip_constant"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_jax.Gradient_Penalty_1Sided.set_Lip_constant" title="Link to this definition"></a></dt>
<dd><p>Sets the target Lipschitz constant.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>L</strong> – New Lipschitz constant.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="Divergences_jax.Gradient_Penalty_2Sided">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">Divergences_jax.</span></span><span class="sig-name descname"><span class="pre">Gradient_Penalty_2Sided</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">penalty_weight</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Lip_const</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_jax.html#Gradient_Penalty_2Sided"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_jax.Gradient_Penalty_2Sided" title="Link to this definition"></a></dt>
<dd><p>Two-sided gradient penalty to enforce a constraint: Lipschitz constant = Lip_const.</p>
<dl class="py method">
<dt class="sig sig-object py" id="Divergences_jax.Gradient_Penalty_2Sided.evaluate">
<span class="sig-name descname"><span class="pre">evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">discriminator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout_rng</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_jax.html#Gradient_Penalty_2Sided.evaluate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_jax.Gradient_Penalty_2Sided.evaluate" title="Link to this definition"></a></dt>
<dd><p>Computes the two-sided gradient penalty to enforce the Lipschitz constant constraint.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>discriminator</strong> – Discriminator model.</p></li>
<li><p><strong>x</strong> – Samples from distribution P.</p></li>
<li><p><strong>y</strong> – Samples from distribution Q.</p></li>
<li><p><strong>params</strong> – Discriminator parameters.</p></li>
<li><p><strong>labels</strong> – Optional input labels.</p></li>
<li><p><strong>dropout_rng</strong> – Optional dropout key for stochasticity.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Two-sided gradient penalty value.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_jax.Gradient_Penalty_2Sided.get_Lip_constant">
<span class="sig-name descname"><span class="pre">get_Lip_constant</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_jax.html#Gradient_Penalty_2Sided.get_Lip_constant"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_jax.Gradient_Penalty_2Sided.get_Lip_constant" title="Link to this definition"></a></dt>
<dd><p>Returns the target Lipschitz constant.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Lipschitz constant.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_jax.Gradient_Penalty_2Sided.set_Lip_constant">
<span class="sig-name descname"><span class="pre">set_Lip_constant</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">L</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_jax.html#Gradient_Penalty_2Sided.set_Lip_constant"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_jax.Gradient_Penalty_2Sided.set_Lip_constant" title="Link to this definition"></a></dt>
<dd><p>Sets the target Lipschitz constant.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>L</strong> – New Lipschitz constant.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="Divergences_jax.IPM">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">Divergences_jax.</span></span><span class="sig-name descname"><span class="pre">IPM</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">discriminator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">disc_optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">discriminator_penalty</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_jax.html#IPM"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_jax.IPM" title="Link to this definition"></a></dt>
<dd><p>IPM (Integral Probability Metrics) class, a subclass of Divergence.
Evaluates the IPM between distributions P and Q using a variational formula.</p>
<dl class="py method">
<dt class="sig sig-object py" id="Divergences_jax.IPM.eval_var_formula">
<span class="sig-name descname"><span class="pre">eval_var_formula</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vars</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout_rng</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_jax.html#IPM.eval_var_formula"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_jax.IPM.eval_var_formula" title="Link to this definition"></a></dt>
<dd><p>Evaluates the variational formula for IPM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Samples from distribution P.</p></li>
<li><p><strong>y</strong> – Samples from distribution Q.</p></li>
<li><p><strong>params</strong> – Discriminator parameters.</p></li>
<li><p><strong>vars</strong> – Additional discriminator variables.</p></li>
<li><p><strong>labels</strong> – Optional input labels.</p></li>
<li><p><strong>dropout_rng</strong> – Optional dropout key for stochasticity.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Tuple of divergence loss and updated variables.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_jax.IPM.eval_var_formula_gen">
<span class="sig-name descname"><span class="pre">eval_var_formula_gen</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vars</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout_rng</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_jax.html#IPM.eval_var_formula_gen"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_jax.IPM.eval_var_formula_gen" title="Link to this definition"></a></dt>
<dd><p>Evaluates the variational formula for IPM when applied to a generator model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Generated samples.</p></li>
<li><p><strong>params</strong> – Discriminator parameters.</p></li>
<li><p><strong>vars</strong> – Additional discriminator variables.</p></li>
<li><p><strong>labels</strong> – Optional input labels.</p></li>
<li><p><strong>dropout_rng</strong> – Optional dropout key for stochasticity.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Tuple of generator loss and updated variables.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="Divergences_jax.Jensen_Shannon_LT">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">Divergences_jax.</span></span><span class="sig-name descname"><span class="pre">Jensen_Shannon_LT</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">discriminator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">disc_optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">discriminator_penalty</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_jax.html#Jensen_Shannon_LT"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_jax.Jensen_Shannon_LT" title="Link to this definition"></a></dt>
<dd><p>Jensen-Shannon divergence class based on the Legendre transform.
JS(P||Q), x~P, y~Q.</p>
<dl class="py method">
<dt class="sig sig-object py" id="Divergences_jax.Jensen_Shannon_LT.f_star">
<span class="sig-name descname"><span class="pre">f_star</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_jax.html#Jensen_Shannon_LT.f_star"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_jax.Jensen_Shannon_LT.f_star" title="Link to this definition"></a></dt>
<dd><p>Legendre transform of f(y) = y * log(y) - (y + 1) * log((y + 1) / 2).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>y</strong> – Input to the Legendre transform.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Transformed value.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_jax.Jensen_Shannon_LT.final_layer_activation">
<span class="sig-name descname"><span class="pre">final_layer_activation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_jax.html#Jensen_Shannon_LT.final_layer_activation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_jax.Jensen_Shannon_LT.final_layer_activation" title="Link to this definition"></a></dt>
<dd><p>Final layer activation function for Jensen-Shannon divergence.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>y</strong> – Input to the activation function.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Activated output.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="Divergences_jax.KLD_DV">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">Divergences_jax.</span></span><span class="sig-name descname"><span class="pre">KLD_DV</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">discriminator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">disc_optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">discriminator_penalty</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_jax.html#KLD_DV"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_jax.KLD_DV" title="Link to this definition"></a></dt>
<dd><p>KL Divergence class based on the Donsker-Varadhan variational formula.
KL(P||Q), x~P, y~Q.</p>
<dl class="py method">
<dt class="sig sig-object py" id="Divergences_jax.KLD_DV.eval_var_formula">
<span class="sig-name descname"><span class="pre">eval_var_formula</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vars</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout_rng</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_jax.html#KLD_DV.eval_var_formula"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_jax.KLD_DV.eval_var_formula" title="Link to this definition"></a></dt>
<dd><p>Evaluates the variational formula for KL divergence.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Samples from distribution P.</p></li>
<li><p><strong>y</strong> – Samples from distribution Q.</p></li>
<li><p><strong>params</strong> – Discriminator parameters.</p></li>
<li><p><strong>vars</strong> – Additional discriminator variables.</p></li>
<li><p><strong>labels</strong> – Optional input labels.</p></li>
<li><p><strong>dropout_rng</strong> – Optional dropout key for stochasticity.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Tuple of KL divergence loss and updated variables.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_jax.KLD_DV.eval_var_formula_gen">
<span class="sig-name descname"><span class="pre">eval_var_formula_gen</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vars</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout_rng</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_jax.html#KLD_DV.eval_var_formula_gen"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_jax.KLD_DV.eval_var_formula_gen" title="Link to this definition"></a></dt>
<dd><p>Evaluates the variational formula for KL divergence applied to a generator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Generated samples.</p></li>
<li><p><strong>params</strong> – Discriminator parameters.</p></li>
<li><p><strong>vars</strong> – Additional discriminator variables.</p></li>
<li><p><strong>labels</strong> – Optional input labels.</p></li>
<li><p><strong>dropout_rng</strong> – Optional dropout key for stochasticity.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Tuple of generator loss and updated variables.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="Divergences_jax.KLD_LT">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">Divergences_jax.</span></span><span class="sig-name descname"><span class="pre">KLD_LT</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">discriminator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">disc_optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">discriminator_penalty</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_jax.html#KLD_LT"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_jax.KLD_LT" title="Link to this definition"></a></dt>
<dd><p>Kullback-Leibler (KL) Divergence class based on the Legendre transform.
KL(P||Q), x~P, y~Q.</p>
<dl class="py method">
<dt class="sig sig-object py" id="Divergences_jax.KLD_LT.f_star">
<span class="sig-name descname"><span class="pre">f_star</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_jax.html#KLD_LT.f_star"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_jax.KLD_LT.f_star" title="Link to this definition"></a></dt>
<dd><p>Legendre transform of f(y) = y * log(y).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>y</strong> – Input to the Legendre transform.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Transformed value.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="Divergences_jax.Pearson_chi_squared_HCR">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">Divergences_jax.</span></span><span class="sig-name descname"><span class="pre">Pearson_chi_squared_HCR</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">discriminator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">disc_optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">discriminator_penalty</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_jax.html#Pearson_chi_squared_HCR"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_jax.Pearson_chi_squared_HCR" title="Link to this definition"></a></dt>
<dd><p>Pearson chi-squared divergence class based on the Hammersley-Chapman-Robbins bound.
chi^2(P||Q), x~P, y~Q.</p>
<dl class="py method">
<dt class="sig sig-object py" id="Divergences_jax.Pearson_chi_squared_HCR.eval_var_formula">
<span class="sig-name descname"><span class="pre">eval_var_formula</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vars</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout_rng</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_jax.html#Pearson_chi_squared_HCR.eval_var_formula"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_jax.Pearson_chi_squared_HCR.eval_var_formula" title="Link to this definition"></a></dt>
<dd><p>Evaluates the variational formula for Pearson chi-squared divergence based on the Hammersley-Chapman-Robbins bound.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Samples from distribution P.</p></li>
<li><p><strong>y</strong> – Samples from distribution Q.</p></li>
<li><p><strong>labels</strong> – Optional labels for the input data.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Pearson chi-squared divergence loss.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_jax.Pearson_chi_squared_HCR.eval_var_formula_gen">
<span class="sig-name descname"><span class="pre">eval_var_formula_gen</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vars</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout_rng</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_jax.html#Pearson_chi_squared_HCR.eval_var_formula_gen"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_jax.Pearson_chi_squared_HCR.eval_var_formula_gen" title="Link to this definition"></a></dt>
<dd><p>Evaluates the generator’s objective based on Pearson chi-squared divergence.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="Divergences_jax.Pearson_chi_squared_LT">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">Divergences_jax.</span></span><span class="sig-name descname"><span class="pre">Pearson_chi_squared_LT</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">discriminator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">disc_optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">discriminator_penalty</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_jax.html#Pearson_chi_squared_LT"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_jax.Pearson_chi_squared_LT" title="Link to this definition"></a></dt>
<dd><p>Pearson chi-squared divergence class based on the Legendre transform.
chi^2(P||Q), x~P, y~Q.</p>
<dl class="py method">
<dt class="sig sig-object py" id="Divergences_jax.Pearson_chi_squared_LT.f_star">
<span class="sig-name descname"><span class="pre">f_star</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_jax.html#Pearson_chi_squared_LT.f_star"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_jax.Pearson_chi_squared_LT.f_star" title="Link to this definition"></a></dt>
<dd><p>Legendre transform of f(y) = (y - 1)^2.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>y</strong> – Input to the Legendre transform.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Transformed value.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="Divergences_jax.Renyi_Divergence">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">Divergences_jax.</span></span><span class="sig-name descname"><span class="pre">Renyi_Divergence</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">discriminator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">disc_optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">discriminator_penalty</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_jax.html#Renyi_Divergence"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_jax.Renyi_Divergence" title="Link to this definition"></a></dt>
<dd><p>Renyi divergence class, a subclass of Divergence.
R_alpha(P||Q), x~P, y~Q.</p>
<dl class="py method">
<dt class="sig sig-object py" id="Divergences_jax.Renyi_Divergence.get_order">
<span class="sig-name descname"><span class="pre">get_order</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_jax.html#Renyi_Divergence.get_order"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_jax.Renyi_Divergence.get_order" title="Link to this definition"></a></dt>
<dd><p>Returns the order of the Renyi divergence.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Alpha order.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_jax.Renyi_Divergence.set_order">
<span class="sig-name descname"><span class="pre">set_order</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">alpha</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_jax.html#Renyi_Divergence.set_order"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_jax.Renyi_Divergence.set_order" title="Link to this definition"></a></dt>
<dd><p>Sets the order of the Renyi divergence.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>alpha</strong> – New alpha order.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="Divergences_jax.Renyi_Divergence_CC">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">Divergences_jax.</span></span><span class="sig-name descname"><span class="pre">Renyi_Divergence_CC</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">discriminator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">disc_optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">final_act_func</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">discriminator_penalty</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_jax.html#Renyi_Divergence_CC"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_jax.Renyi_Divergence_CC" title="Link to this definition"></a></dt>
<dd><p>Renyi divergence class based on the convex-conjugate variational formula.
R_alpha(P||Q), x~P, y~Q.</p>
<dl class="py method">
<dt class="sig sig-object py" id="Divergences_jax.Renyi_Divergence_CC.eval_var_formula">
<span class="sig-name descname"><span class="pre">eval_var_formula</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vars</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout_rng</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_jax.html#Renyi_Divergence_CC.eval_var_formula"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_jax.Renyi_Divergence_CC.eval_var_formula" title="Link to this definition"></a></dt>
<dd><p>Evaluates the variational formula of Renyi divergence using the convex-conjugate variational formula.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Samples from distribution P.</p></li>
<li><p><strong>y</strong> – Samples from distribution Q.</p></li>
<li><p><strong>params</strong> – Discriminator parameters.</p></li>
<li><p><strong>vars</strong> – Additional discriminator variables.</p></li>
<li><p><strong>labels</strong> – Optional input labels.</p></li>
<li><p><strong>dropout_rng</strong> – Optional dropout key for stochasticity.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Tuple of Renyi divergence loss and updated variables.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_jax.Renyi_Divergence_CC.eval_var_formula_gen">
<span class="sig-name descname"><span class="pre">eval_var_formula_gen</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vars</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout_rng</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_jax.html#Renyi_Divergence_CC.eval_var_formula_gen"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_jax.Renyi_Divergence_CC.eval_var_formula_gen" title="Link to this definition"></a></dt>
<dd><p>Evaluates the variational formula of Renyi divergence for the generator using the convex-conjugate variational formula.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Generated samples.</p></li>
<li><p><strong>params</strong> – Discriminator parameters.</p></li>
<li><p><strong>vars</strong> – Additional discriminator variables.</p></li>
<li><p><strong>labels</strong> – Optional input labels.</p></li>
<li><p><strong>dropout_rng</strong> – Optional dropout key for stochasticity.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Tuple of generator loss and updated variables.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_jax.Renyi_Divergence_CC.final_layer_activation">
<span class="sig-name descname"><span class="pre">final_layer_activation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_jax.html#Renyi_Divergence_CC.final_layer_activation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_jax.Renyi_Divergence_CC.final_layer_activation" title="Link to this definition"></a></dt>
<dd><p>Final layer activation function to enforce positive values.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>y</strong> – Output of the discriminator.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Activated output, ensuring positivity based on the final activation function.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="Divergences_jax.Renyi_Divergence_CC_rescaled">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">Divergences_jax.</span></span><span class="sig-name descname"><span class="pre">Renyi_Divergence_CC_rescaled</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">discriminator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">disc_optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">final_act_func</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">discriminator_penalty</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_jax.html#Renyi_Divergence_CC_rescaled"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_jax.Renyi_Divergence_CC_rescaled" title="Link to this definition"></a></dt>
<dd><p>Rescaled Renyi divergence class based on the rescaled convex-conjugate variational formula.
alpha * R_alpha(P||Q), x~P, y~Q.</p>
<dl class="py method">
<dt class="sig sig-object py" id="Divergences_jax.Renyi_Divergence_CC_rescaled.eval_var_formula">
<span class="sig-name descname"><span class="pre">eval_var_formula</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vars</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout_rng</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_jax.html#Renyi_Divergence_CC_rescaled.eval_var_formula"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_jax.Renyi_Divergence_CC_rescaled.eval_var_formula" title="Link to this definition"></a></dt>
<dd><p>Evaluates the variational formula of the rescaled Renyi divergence.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Samples from distribution P.</p></li>
<li><p><strong>y</strong> – Samples from distribution Q.</p></li>
<li><p><strong>params</strong> – Discriminator parameters.</p></li>
<li><p><strong>vars</strong> – Additional discriminator variables.</p></li>
<li><p><strong>labels</strong> – Optional input labels.</p></li>
<li><p><strong>dropout_rng</strong> – Optional dropout key for stochasticity.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Tuple of rescaled Renyi divergence loss and updated variables.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_jax.Renyi_Divergence_CC_rescaled.eval_var_formula_gen">
<span class="sig-name descname"><span class="pre">eval_var_formula_gen</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vars</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout_rng</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_jax.html#Renyi_Divergence_CC_rescaled.eval_var_formula_gen"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_jax.Renyi_Divergence_CC_rescaled.eval_var_formula_gen" title="Link to this definition"></a></dt>
<dd><p>Evaluates the variational formula for the generator of the rescaled Renyi divergence.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Generated samples.</p></li>
<li><p><strong>params</strong> – Discriminator parameters.</p></li>
<li><p><strong>vars</strong> – Additional discriminator variables.</p></li>
<li><p><strong>labels</strong> – Optional input labels.</p></li>
<li><p><strong>dropout_rng</strong> – Optional dropout key for stochasticity.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Tuple of generator loss and updated variables.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_jax.Renyi_Divergence_CC_rescaled.final_layer_activation">
<span class="sig-name descname"><span class="pre">final_layer_activation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_jax.html#Renyi_Divergence_CC_rescaled.final_layer_activation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_jax.Renyi_Divergence_CC_rescaled.final_layer_activation" title="Link to this definition"></a></dt>
<dd><p>Final layer activation function to enforce positivity, scaled by alpha.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>y</strong> – Output of the discriminator.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Activated output, scaled by the alpha parameter.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="Divergences_jax.Renyi_Divergence_DV">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">Divergences_jax.</span></span><span class="sig-name descname"><span class="pre">Renyi_Divergence_DV</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">discriminator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">disc_optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">discriminator_penalty</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_jax.html#Renyi_Divergence_DV"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_jax.Renyi_Divergence_DV" title="Link to this definition"></a></dt>
<dd><p>Renyi divergence class based on the Renyi-Donsker-Varadhan variational formula.
R_alpha(P||Q), x~P, y~Q.</p>
<dl class="py method">
<dt class="sig sig-object py" id="Divergences_jax.Renyi_Divergence_DV.eval_var_formula">
<span class="sig-name descname"><span class="pre">eval_var_formula</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vars</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout_rng</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_jax.html#Renyi_Divergence_DV.eval_var_formula"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_jax.Renyi_Divergence_DV.eval_var_formula" title="Link to this definition"></a></dt>
<dd><p>Evaluates the variational formula of Renyi divergence.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Samples from distribution P.</p></li>
<li><p><strong>y</strong> – Samples from distribution Q.</p></li>
<li><p><strong>params</strong> – Discriminator parameters.</p></li>
<li><p><strong>vars</strong> – Additional discriminator variables.</p></li>
<li><p><strong>labels</strong> – Optional input labels.</p></li>
<li><p><strong>dropout_rng</strong> – Optional dropout key for stochasticity.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Tuple of Renyi divergence loss and updated variables.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_jax.Renyi_Divergence_DV.eval_var_formula_gen">
<span class="sig-name descname"><span class="pre">eval_var_formula_gen</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vars</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout_rng</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_jax.html#Renyi_Divergence_DV.eval_var_formula_gen"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_jax.Renyi_Divergence_DV.eval_var_formula_gen" title="Link to this definition"></a></dt>
<dd><p>Evaluates the variational formula of Renyi divergence for the generator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Generated samples.</p></li>
<li><p><strong>params</strong> – Discriminator parameters.</p></li>
<li><p><strong>vars</strong> – Additional discriminator variables.</p></li>
<li><p><strong>labels</strong> – Optional input labels.</p></li>
<li><p><strong>dropout_rng</strong> – Optional dropout key for stochasticity.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Tuple of generator loss and updated variables.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="Divergences_jax.Renyi_Divergence_WCR">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">Divergences_jax.</span></span><span class="sig-name descname"><span class="pre">Renyi_Divergence_WCR</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">discriminator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">disc_optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">final_act_func</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">discriminator_penalty</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_jax.html#Renyi_Divergence_WCR"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_jax.Renyi_Divergence_WCR" title="Link to this definition"></a></dt>
<dd><p>Rescaled Renyi divergence class as alpha approaches infinity (worst-case regret divergence).
Dinfty(P||Q), x~P, y~Q.</p>
<dl class="py method">
<dt class="sig sig-object py" id="Divergences_jax.Renyi_Divergence_WCR.eval_var_formula">
<span class="sig-name descname"><span class="pre">eval_var_formula</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vars</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout_rng</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_jax.html#Renyi_Divergence_WCR.eval_var_formula"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_jax.Renyi_Divergence_WCR.eval_var_formula" title="Link to this definition"></a></dt>
<dd><p>Evaluates the variational formula of the Renyi divergence class as alpha approaches infinity (worst-case regret divergence).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Samples from distribution P.</p></li>
<li><p><strong>y</strong> – Samples from distribution Q.</p></li>
<li><p><strong>params</strong> – Discriminator parameters.</p></li>
<li><p><strong>vars</strong> – Additional discriminator variables.</p></li>
<li><p><strong>labels</strong> – Optional input labels.</p></li>
<li><p><strong>dropout_rng</strong> – Optional dropout key for stochasticity.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Tuple of worst-case regret divergence loss and updated variables.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_jax.Renyi_Divergence_WCR.eval_var_formula_gen">
<span class="sig-name descname"><span class="pre">eval_var_formula_gen</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vars</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout_rng</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_jax.html#Renyi_Divergence_WCR.eval_var_formula_gen"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_jax.Renyi_Divergence_WCR.eval_var_formula_gen" title="Link to this definition"></a></dt>
<dd><p>Evaluates the variational formula for the generator of the worst-case regret divergence.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Generated samples.</p></li>
<li><p><strong>params</strong> – Discriminator parameters.</p></li>
<li><p><strong>vars</strong> – Additional discriminator variables.</p></li>
<li><p><strong>labels</strong> – Optional input labels.</p></li>
<li><p><strong>dropout_rng</strong> – Optional dropout key for stochasticity.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Tuple of generator loss and updated variables.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="Divergences_jax.alpha_Divergence_LT">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">Divergences_jax.</span></span><span class="sig-name descname"><span class="pre">alpha_Divergence_LT</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">discriminator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">disc_optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">discriminator_penalty</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_jax.html#alpha_Divergence_LT"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_jax.alpha_Divergence_LT" title="Link to this definition"></a></dt>
<dd><p>Alpha-divergence class based on the Legendre transform.
D_f_alpha(P||Q), x~P, y~Q.</p>
<dl class="py method">
<dt class="sig sig-object py" id="Divergences_jax.alpha_Divergence_LT.f_star">
<span class="sig-name descname"><span class="pre">f_star</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_jax.html#alpha_Divergence_LT.f_star"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_jax.alpha_Divergence_LT.f_star" title="Link to this definition"></a></dt>
<dd><p>Legendre transform of f_alpha based on the alpha value.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>y</strong> – Input to the Legendre transform.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Transformed value.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_jax.alpha_Divergence_LT.get_order">
<span class="sig-name descname"><span class="pre">get_order</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_jax.html#alpha_Divergence_LT.get_order"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_jax.alpha_Divergence_LT.get_order" title="Link to this definition"></a></dt>
<dd><p>Returns the order of the alpha-divergence.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Alpha order.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_jax.alpha_Divergence_LT.set_order">
<span class="sig-name descname"><span class="pre">set_order</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">alpha</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_jax.html#alpha_Divergence_LT.set_order"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_jax.alpha_Divergence_LT.set_order" title="Link to this definition"></a></dt>
<dd><p>Sets the order of the alpha-divergence.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>alpha</strong> – New alpha order.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="Divergences_jax.f_Divergence">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">Divergences_jax.</span></span><span class="sig-name descname"><span class="pre">f_Divergence</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">discriminator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">disc_optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">discriminator_penalty</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_jax.html#f_Divergence"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_jax.f_Divergence" title="Link to this definition"></a></dt>
<dd><p>f-divergence class, parent class for f-divergence-based measures D_f(P||Q).
Subclasses need to implement the Legendre transform of f (f_star).</p>
<dl class="py method">
<dt class="sig sig-object py" id="Divergences_jax.f_Divergence.eval_var_formula">
<span class="sig-name descname"><span class="pre">eval_var_formula</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vars</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout_rng</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_jax.html#f_Divergence.eval_var_formula"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_jax.f_Divergence.eval_var_formula" title="Link to this definition"></a></dt>
<dd><p>Evaluates the variational formula of f-divergence, D_f(P||Q).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Samples from distribution P.</p></li>
<li><p><strong>y</strong> – Samples from distribution Q.</p></li>
<li><p><strong>params</strong> – Discriminator parameters.</p></li>
<li><p><strong>vars</strong> – Additional discriminator variables.</p></li>
<li><p><strong>labels</strong> – Optional input labels.</p></li>
<li><p><strong>dropout_rng</strong> – Optional dropout key for stochasticity.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Tuple of divergence loss and updated variables.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_jax.f_Divergence.eval_var_formula_gen">
<span class="sig-name descname"><span class="pre">eval_var_formula_gen</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vars</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout_rng</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_jax.html#f_Divergence.eval_var_formula_gen"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_jax.f_Divergence.eval_var_formula_gen" title="Link to this definition"></a></dt>
<dd><p>Evaluates the variational formula for f-divergence when applied to a generator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Generated samples.</p></li>
<li><p><strong>params</strong> – Discriminator parameters.</p></li>
<li><p><strong>vars</strong> – Additional discriminator variables.</p></li>
<li><p><strong>labels</strong> – Optional input labels.</p></li>
<li><p><strong>dropout_rng</strong> – Optional dropout key for stochasticity.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Tuple of generator loss and updated variables.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_jax.f_Divergence.f_star">
<span class="sig-name descname"><span class="pre">f_star</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_jax.html#f_Divergence.f_star"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_jax.f_Divergence.f_star" title="Link to this definition"></a></dt>
<dd><p>Placeholder for the Legendre transform of the function f.
Should be implemented by subclasses.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>y</strong> – Input to the Legendre transform.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>None.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_jax.f_Divergence.final_layer_activation">
<span class="sig-name descname"><span class="pre">final_layer_activation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_jax.html#f_Divergence.final_layer_activation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_jax.f_Divergence.final_layer_activation" title="Link to this definition"></a></dt>
<dd><p>Final activation function applied to the output of the discriminator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>y</strong> – Output of the discriminator.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Activated output.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="Divergences_jax.squared_Hellinger_LT">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">Divergences_jax.</span></span><span class="sig-name descname"><span class="pre">squared_Hellinger_LT</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">discriminator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">disc_optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">discriminator_penalty</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_jax.html#squared_Hellinger_LT"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_jax.squared_Hellinger_LT" title="Link to this definition"></a></dt>
<dd><p>Squared Hellinger distance class based on the Legendre transform.
H(P||Q), x~P, y~Q.</p>
<dl class="py method">
<dt class="sig sig-object py" id="Divergences_jax.squared_Hellinger_LT.f_star">
<span class="sig-name descname"><span class="pre">f_star</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_jax.html#squared_Hellinger_LT.f_star"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_jax.squared_Hellinger_LT.f_star" title="Link to this definition"></a></dt>
<dd><p>Legendre transform of f(y) = (sqrt(y) - 1)^2.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>y</strong> – Input to the Legendre transform.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Transformed value.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_jax.squared_Hellinger_LT.final_layer_activation">
<span class="sig-name descname"><span class="pre">final_layer_activation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_jax.html#squared_Hellinger_LT.final_layer_activation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_jax.squared_Hellinger_LT.final_layer_activation" title="Link to this definition"></a></dt>
<dd><p>Final layer activation for squared Hellinger distance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>y</strong> – Input to the activation function.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Activated output.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class" id="module-Divergences_tf">
<dt class="sig sig-object py" id="Divergences_tf.Discriminator_Penalty">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">Divergences_tf.</span></span><span class="sig-name descname"><span class="pre">Discriminator_Penalty</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">penalty_weight</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_tf.html#Discriminator_Penalty"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_tf.Discriminator_Penalty" title="Link to this definition"></a></dt>
<dd><p>Discriminator penalty class penalizes the divergence objective functional during training.
Allows for the (approximate) implementation of discriminator constraints.</p>
<dl class="py method">
<dt class="sig sig-object py" id="Divergences_tf.Discriminator_Penalty.evaluate">
<span class="sig-name descname"><span class="pre">evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">discriminator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_tf.html#Discriminator_Penalty.evaluate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_tf.Discriminator_Penalty.evaluate" title="Link to this definition"></a></dt>
<dd><p>Evaluates the penalty term. Should be overridden by subclasses.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>discriminator</strong> – Discriminator model.</p></li>
<li><p><strong>x</strong> – Samples from distribution P.</p></li>
<li><p><strong>y</strong> – Samples from distribution Q.</p></li>
<li><p><strong>labels</strong> – Optional labels for the input data.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>None. (Subclasses should implement penalty evaluation.)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_tf.Discriminator_Penalty.get_penalty_weight">
<span class="sig-name descname"><span class="pre">get_penalty_weight</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_tf.html#Discriminator_Penalty.get_penalty_weight"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_tf.Discriminator_Penalty.get_penalty_weight" title="Link to this definition"></a></dt>
<dd><p>Returns the weight of the penalty term.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_tf.Discriminator_Penalty.set_penalty_weight">
<span class="sig-name descname"><span class="pre">set_penalty_weight</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">weight</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_tf.html#Discriminator_Penalty.set_penalty_weight"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_tf.Discriminator_Penalty.set_penalty_weight" title="Link to this definition"></a></dt>
<dd><p>Sets the weight of the penalty term.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="Divergences_tf.Divergence">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">Divergences_tf.</span></span><span class="sig-name descname"><span class="pre">Divergence</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_tf.html#Divergence"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_tf.Divergence" title="Link to this definition"></a></dt>
<dd><p>Divergence D(P||Q) between random variables x~P, y~Q.
Parent class where common parameters and functions are defined.</p>
<dl class="py method">
<dt class="sig sig-object py" id="Divergences_tf.Divergence.discriminate">
<span class="sig-name descname"><span class="pre">discriminate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_tf.html#Divergence.discriminate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_tf.Divergence.discriminate" title="Link to this definition"></a></dt>
<dd><p>Discriminates between samples from distributions P and Q.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Input data to discriminate.</p></li>
<li><p><strong>labels</strong> – Optional labels for the input data.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Discriminator output.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_tf.Divergence.discriminator_loss">
<span class="sig-name descname"><span class="pre">discriminator_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_tf.html#Divergence.discriminator_loss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_tf.Divergence.discriminator_loss" title="Link to this definition"></a></dt>
<dd><p>Computes the discriminator loss.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Samples from distribution P.</p></li>
<li><p><strong>y</strong> – Samples from distribution Q.</p></li>
<li><p><strong>labels</strong> – Optional labels for the input data.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Discriminator loss.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_tf.Divergence.estimate">
<span class="sig-name descname"><span class="pre">estimate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_tf.html#Divergence.estimate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_tf.Divergence.estimate" title="Link to this definition"></a></dt>
<dd><p>Estimates the divergence measure.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Samples from distribution P.</p></li>
<li><p><strong>y</strong> – Samples from distribution Q.</p></li>
<li><p><strong>labels</strong> – Optional labels for the input data.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Estimated divergence loss.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_tf.Divergence.eval_var_formula">
<span class="sig-name descname"><span class="pre">eval_var_formula</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_tf.html#Divergence.eval_var_formula"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_tf.Divergence.eval_var_formula" title="Link to this definition"></a></dt>
<dd><p>Evaluates the variational formula for the divergence measure.
Should be implemented by subclasses.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Samples from distribution P.</p></li>
<li><p><strong>y</strong> – Samples from distribution Q.</p></li>
<li><p><strong>labels</strong> – Optional labels for the input data.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>None (to be overridden by subclasses).</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_tf.Divergence.generator_loss">
<span class="sig-name descname"><span class="pre">generator_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_tf.html#Divergence.generator_loss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_tf.Divergence.generator_loss" title="Link to this definition"></a></dt>
<dd><p>Computes the generator loss.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Generated samples.</p></li>
<li><p><strong>labels</strong> – Optional labels for the input data.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Generator loss.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_tf.Divergence.get_batch_size">
<span class="sig-name descname"><span class="pre">get_batch_size</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_tf.html#Divergence.get_batch_size"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_tf.Divergence.get_batch_size" title="Link to this definition"></a></dt>
<dd><p>Returns the batch size.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_tf.Divergence.get_discriminator">
<span class="sig-name descname"><span class="pre">get_discriminator</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_tf.html#Divergence.get_discriminator"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_tf.Divergence.get_discriminator" title="Link to this definition"></a></dt>
<dd><p>Returns the discriminator model.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_tf.Divergence.get_learning_rate">
<span class="sig-name descname"><span class="pre">get_learning_rate</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_tf.html#Divergence.get_learning_rate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_tf.Divergence.get_learning_rate" title="Link to this definition"></a></dt>
<dd><p>Returns the learning rate.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_tf.Divergence.get_no_epochs">
<span class="sig-name descname"><span class="pre">get_no_epochs</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_tf.html#Divergence.get_no_epochs"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_tf.Divergence.get_no_epochs" title="Link to this definition"></a></dt>
<dd><p>Returns the number of training epochs.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_tf.Divergence.set_batch_size">
<span class="sig-name descname"><span class="pre">set_batch_size</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">BATCH_SIZE</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_tf.html#Divergence.set_batch_size"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_tf.Divergence.set_batch_size" title="Link to this definition"></a></dt>
<dd><p>Sets the batch size.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_tf.Divergence.set_discriminator">
<span class="sig-name descname"><span class="pre">set_discriminator</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">discriminator</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_tf.html#Divergence.set_discriminator"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_tf.Divergence.set_discriminator" title="Link to this definition"></a></dt>
<dd><p>Sets a new discriminator model.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_tf.Divergence.set_learning_rate">
<span class="sig-name descname"><span class="pre">set_learning_rate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">lr</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_tf.html#Divergence.set_learning_rate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_tf.Divergence.set_learning_rate" title="Link to this definition"></a></dt>
<dd><p>Sets the learning rate.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_tf.Divergence.set_no_epochs">
<span class="sig-name descname"><span class="pre">set_no_epochs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">epochs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_tf.html#Divergence.set_no_epochs"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_tf.Divergence.set_no_epochs" title="Link to this definition"></a></dt>
<dd><p>Sets the number of training epochs.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_tf.Divergence.train">
<span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_P</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_Q</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_estimates</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_tf.html#Divergence.train"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_tf.Divergence.train" title="Link to this definition"></a></dt>
<dd><p>Trains the model for a number of epochs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data_P</strong> – Data samples from distribution P.</p></li>
<li><p><strong>data_Q</strong> – Data samples from distribution Q.</p></li>
<li><p><strong>labels</strong> – Optional labels for the input data.</p></li>
<li><p><strong>save_estimates</strong> – Whether to save divergence estimates.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A list of divergence estimates for each epoch.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_tf.Divergence.train_step">
<span class="sig-name descname"><span class="pre">train_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_tf.html#Divergence.train_step"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_tf.Divergence.train_step" title="Link to this definition"></a></dt>
<dd><p>Performs a training step for the discriminator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Samples from distribution P.</p></li>
<li><p><strong>y</strong> – Samples from distribution Q.</p></li>
<li><p><strong>labels</strong> – Optional labels for the input data.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Loss value for the current step.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="Divergences_tf.Gradient_Penalty_1Sided">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">Divergences_tf.</span></span><span class="sig-name descname"><span class="pre">Gradient_Penalty_1Sided</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">penalty_weight</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Lip_const</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_tf.html#Gradient_Penalty_1Sided"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_tf.Gradient_Penalty_1Sided" title="Link to this definition"></a></dt>
<dd><p>One-sided gradient penalty class to enforce the Lipschitz constant &lt;= Lip_const.</p>
<dl class="py method">
<dt class="sig sig-object py" id="Divergences_tf.Gradient_Penalty_1Sided.evaluate">
<span class="sig-name descname"><span class="pre">evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">discriminator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_tf.html#Gradient_Penalty_1Sided.evaluate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_tf.Gradient_Penalty_1Sided.evaluate" title="Link to this definition"></a></dt>
<dd><p>Computes the one-sided gradient penalty to enforce the Lipschitz constant &lt;= Lip_const.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>discriminator</strong> – Discriminator model.</p></li>
<li><p><strong>x</strong> – Samples from distribution P.</p></li>
<li><p><strong>y</strong> – Samples from distribution Q.</p></li>
<li><p><strong>labels</strong> – Optional labels for the input data.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>One-sided gradient penalty value.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_tf.Gradient_Penalty_1Sided.get_Lip_constant">
<span class="sig-name descname"><span class="pre">get_Lip_constant</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_tf.html#Gradient_Penalty_1Sided.get_Lip_constant"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_tf.Gradient_Penalty_1Sided.get_Lip_constant" title="Link to this definition"></a></dt>
<dd><p>Returns the target Lipschitz constant.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_tf.Gradient_Penalty_1Sided.set_Lip_constant">
<span class="sig-name descname"><span class="pre">set_Lip_constant</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">L</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_tf.html#Gradient_Penalty_1Sided.set_Lip_constant"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_tf.Gradient_Penalty_1Sided.set_Lip_constant" title="Link to this definition"></a></dt>
<dd><p>Sets the target Lipschitz constant.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="Divergences_tf.Gradient_Penalty_2Sided">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">Divergences_tf.</span></span><span class="sig-name descname"><span class="pre">Gradient_Penalty_2Sided</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">penalty_weight</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Lip_const</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_tf.html#Gradient_Penalty_2Sided"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_tf.Gradient_Penalty_2Sided" title="Link to this definition"></a></dt>
<dd><p>Two-sided gradient penalty class to enforce the Lipschitz constant = Lip_const.</p>
<dl class="py method">
<dt class="sig sig-object py" id="Divergences_tf.Gradient_Penalty_2Sided.evaluate">
<span class="sig-name descname"><span class="pre">evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">discriminator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_tf.html#Gradient_Penalty_2Sided.evaluate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_tf.Gradient_Penalty_2Sided.evaluate" title="Link to this definition"></a></dt>
<dd><p>Computes the two-sided gradient penalty to enforce the Lipschitz constant = Lip_const.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>discriminator</strong> – Discriminator model.</p></li>
<li><p><strong>x</strong> – Samples from distribution P.</p></li>
<li><p><strong>y</strong> – Samples from distribution Q.</p></li>
<li><p><strong>labels</strong> – Optional labels for the input data.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Two-sided gradient penalty value.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_tf.Gradient_Penalty_2Sided.get_Lip_constant">
<span class="sig-name descname"><span class="pre">get_Lip_constant</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_tf.html#Gradient_Penalty_2Sided.get_Lip_constant"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_tf.Gradient_Penalty_2Sided.get_Lip_constant" title="Link to this definition"></a></dt>
<dd><p>Returns the target Lipschitz constant.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_tf.Gradient_Penalty_2Sided.set_Lip_constant">
<span class="sig-name descname"><span class="pre">set_Lip_constant</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">L</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_tf.html#Gradient_Penalty_2Sided.set_Lip_constant"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_tf.Gradient_Penalty_2Sided.set_Lip_constant" title="Link to this definition"></a></dt>
<dd><p>Sets the target Lipschitz constant.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="Divergences_tf.IPM">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">Divergences_tf.</span></span><span class="sig-name descname"><span class="pre">IPM</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_tf.html#IPM"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_tf.IPM" title="Link to this definition"></a></dt>
<dd><p>Integral Probability Metric (IPM) class for evaluating IPMs.</p>
<dl class="py method">
<dt class="sig sig-object py" id="Divergences_tf.IPM.eval_var_formula">
<span class="sig-name descname"><span class="pre">eval_var_formula</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_tf.html#IPM.eval_var_formula"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_tf.IPM.eval_var_formula" title="Link to this definition"></a></dt>
<dd><p>Evaluates the variational formula for IPM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Samples from distribution P.</p></li>
<li><p><strong>y</strong> – Samples from distribution Q.</p></li>
<li><p><strong>labels</strong> – Optional labels for the input data.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>IPM loss.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_tf.IPM.eval_var_formula_gen">
<span class="sig-name descname"><span class="pre">eval_var_formula_gen</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_tf.html#IPM.eval_var_formula_gen"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_tf.IPM.eval_var_formula_gen" title="Link to this definition"></a></dt>
<dd><p>Evaluates the variational formula for IPM applied to the generator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Generated samples.</p></li>
<li><p><strong>labels</strong> – Optional labels for the input data.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Generator loss based on IPM.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="Divergences_tf.Jensen_Shannon_LT">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">Divergences_tf.</span></span><span class="sig-name descname"><span class="pre">Jensen_Shannon_LT</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_tf.html#Jensen_Shannon_LT"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_tf.Jensen_Shannon_LT" title="Link to this definition"></a></dt>
<dd><p>Jensen-Shannon divergence class based on the Legendre transform.
JS(P||Q), x~P, y~Q.</p>
<dl class="py method">
<dt class="sig sig-object py" id="Divergences_tf.Jensen_Shannon_LT.f_star">
<span class="sig-name descname"><span class="pre">f_star</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_tf.html#Jensen_Shannon_LT.f_star"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_tf.Jensen_Shannon_LT.f_star" title="Link to this definition"></a></dt>
<dd><p>Legendre transform of f(y) = y * log(y) - (y + 1) * log((y + 1) / 2).</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_tf.Jensen_Shannon_LT.final_layer_activation">
<span class="sig-name descname"><span class="pre">final_layer_activation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_tf.html#Jensen_Shannon_LT.final_layer_activation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_tf.Jensen_Shannon_LT.final_layer_activation" title="Link to this definition"></a></dt>
<dd><p>Applies the final layer activation for Jensen-Shannon divergence.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="Divergences_tf.KLD_DV">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">Divergences_tf.</span></span><span class="sig-name descname"><span class="pre">KLD_DV</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_tf.html#KLD_DV"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_tf.KLD_DV" title="Link to this definition"></a></dt>
<dd><p>KL divergence class based on the Donsker-Varadhan variational formula.
KL(P||Q), x~P, y~Q.</p>
<dl class="py method">
<dt class="sig sig-object py" id="Divergences_tf.KLD_DV.eval_var_formula">
<span class="sig-name descname"><span class="pre">eval_var_formula</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_tf.html#KLD_DV.eval_var_formula"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_tf.KLD_DV.eval_var_formula" title="Link to this definition"></a></dt>
<dd><p>Evaluates the variational formula for KL divergence.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Samples from distribution P.</p></li>
<li><p><strong>y</strong> – Samples from distribution Q.</p></li>
<li><p><strong>labels</strong> – Optional labels for the input data.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>KL divergence loss.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_tf.KLD_DV.eval_var_formula_gen">
<span class="sig-name descname"><span class="pre">eval_var_formula_gen</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_tf.html#KLD_DV.eval_var_formula_gen"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_tf.KLD_DV.eval_var_formula_gen" title="Link to this definition"></a></dt>
<dd><p>Evaluates the generator’s objective based on KL divergence.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="Divergences_tf.KLD_LT">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">Divergences_tf.</span></span><span class="sig-name descname"><span class="pre">KLD_LT</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_tf.html#KLD_LT"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_tf.KLD_LT" title="Link to this definition"></a></dt>
<dd><p>Kullback-Leibler (KL) divergence class based on the Legendre transform.
KL(P||Q), x~P, y~Q.</p>
<dl class="py method">
<dt class="sig sig-object py" id="Divergences_tf.KLD_LT.f_star">
<span class="sig-name descname"><span class="pre">f_star</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_tf.html#KLD_LT.f_star"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_tf.KLD_LT.f_star" title="Link to this definition"></a></dt>
<dd><p>Legendre transform of f(y) = y * log(y).</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="Divergences_tf.Pearson_chi_squared_HCR">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">Divergences_tf.</span></span><span class="sig-name descname"><span class="pre">Pearson_chi_squared_HCR</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_tf.html#Pearson_chi_squared_HCR"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_tf.Pearson_chi_squared_HCR" title="Link to this definition"></a></dt>
<dd><p>Pearson chi-squared divergence class based on the Hammersley-Chapman-Robbins bound.
chi^2(P||Q), x~P, y~Q.</p>
<dl class="py method">
<dt class="sig sig-object py" id="Divergences_tf.Pearson_chi_squared_HCR.eval_var_formula">
<span class="sig-name descname"><span class="pre">eval_var_formula</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_tf.html#Pearson_chi_squared_HCR.eval_var_formula"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_tf.Pearson_chi_squared_HCR.eval_var_formula" title="Link to this definition"></a></dt>
<dd><p>Evaluates the variational formula for Pearson chi-squared divergence based on the Hammersley-Chapman-Robbins bound.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Samples from distribution P.</p></li>
<li><p><strong>y</strong> – Samples from distribution Q.</p></li>
<li><p><strong>labels</strong> – Optional labels for the input data.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Pearson chi-squared divergence loss.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_tf.Pearson_chi_squared_HCR.eval_var_formula_gen">
<span class="sig-name descname"><span class="pre">eval_var_formula_gen</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_tf.html#Pearson_chi_squared_HCR.eval_var_formula_gen"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_tf.Pearson_chi_squared_HCR.eval_var_formula_gen" title="Link to this definition"></a></dt>
<dd><p>Evaluates the generator’s objective based on Pearson chi-squared divergence.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="Divergences_tf.Pearson_chi_squared_LT">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">Divergences_tf.</span></span><span class="sig-name descname"><span class="pre">Pearson_chi_squared_LT</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_tf.html#Pearson_chi_squared_LT"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_tf.Pearson_chi_squared_LT" title="Link to this definition"></a></dt>
<dd><p>Pearson chi-squared divergence class based on the Legendre transform.
chi^2(P||Q), x~P, y~Q.</p>
<dl class="py method">
<dt class="sig sig-object py" id="Divergences_tf.Pearson_chi_squared_LT.f_star">
<span class="sig-name descname"><span class="pre">f_star</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_tf.html#Pearson_chi_squared_LT.f_star"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_tf.Pearson_chi_squared_LT.f_star" title="Link to this definition"></a></dt>
<dd><p>Legendre transform of f(y) = (y - 1)^2.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="Divergences_tf.Renyi_Divergence">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">Divergences_tf.</span></span><span class="sig-name descname"><span class="pre">Renyi_Divergence</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_tf.html#Renyi_Divergence"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_tf.Renyi_Divergence" title="Link to this definition"></a></dt>
<dd><p>Renyi divergence class for computing Renyi divergence R_alpha(P||Q), x~P, y~Q.</p>
<dl class="py method">
<dt class="sig sig-object py" id="Divergences_tf.Renyi_Divergence.get_order">
<span class="sig-name descname"><span class="pre">get_order</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_tf.html#Renyi_Divergence.get_order"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_tf.Renyi_Divergence.get_order" title="Link to this definition"></a></dt>
<dd><p>Returns the order of the Renyi divergence.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_tf.Renyi_Divergence.set_order">
<span class="sig-name descname"><span class="pre">set_order</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">alpha</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_tf.html#Renyi_Divergence.set_order"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_tf.Renyi_Divergence.set_order" title="Link to this definition"></a></dt>
<dd><p>Sets the order of the Renyi divergence.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="Divergences_tf.Renyi_Divergence_CC">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">Divergences_tf.</span></span><span class="sig-name descname"><span class="pre">Renyi_Divergence_CC</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_tf.html#Renyi_Divergence_CC"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_tf.Renyi_Divergence_CC" title="Link to this definition"></a></dt>
<dd><p>Renyi divergence class based on the convex-conjugate variational formula.
R_alpha(P||Q), x~P, y~Q.</p>
<dl class="py method">
<dt class="sig sig-object py" id="Divergences_tf.Renyi_Divergence_CC.eval_var_formula">
<span class="sig-name descname"><span class="pre">eval_var_formula</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_tf.html#Renyi_Divergence_CC.eval_var_formula"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_tf.Renyi_Divergence_CC.eval_var_formula" title="Link to this definition"></a></dt>
<dd><p>Evaluates the variational formula for Renyi divergence based on the convex-conjugate formula.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Samples from distribution P.</p></li>
<li><p><strong>y</strong> – Samples from distribution Q.</p></li>
<li><p><strong>labels</strong> – Optional labels for the input data.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Renyi divergence loss.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_tf.Renyi_Divergence_CC.eval_var_formula_gen">
<span class="sig-name descname"><span class="pre">eval_var_formula_gen</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_tf.html#Renyi_Divergence_CC.eval_var_formula_gen"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_tf.Renyi_Divergence_CC.eval_var_formula_gen" title="Link to this definition"></a></dt>
<dd><p>Evaluates the generator’s objective based on Renyi divergence using the convex-conjugate formula.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_tf.Renyi_Divergence_CC.final_layer_activation">
<span class="sig-name descname"><span class="pre">final_layer_activation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_tf.html#Renyi_Divergence_CC.final_layer_activation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_tf.Renyi_Divergence_CC.final_layer_activation" title="Link to this definition"></a></dt>
<dd><p>Applies the final layer activation to enforce positive values.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="Divergences_tf.Renyi_Divergence_CC_rescaled">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">Divergences_tf.</span></span><span class="sig-name descname"><span class="pre">Renyi_Divergence_CC_rescaled</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_tf.html#Renyi_Divergence_CC_rescaled"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_tf.Renyi_Divergence_CC_rescaled" title="Link to this definition"></a></dt>
<dd><p>Rescaled Renyi divergence class based on the rescaled convex-conjugate variational formula.
alpha * R_alpha(P||Q), x~P, y~Q.</p>
<dl class="py method">
<dt class="sig sig-object py" id="Divergences_tf.Renyi_Divergence_CC_rescaled.eval_var_formula">
<span class="sig-name descname"><span class="pre">eval_var_formula</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_tf.html#Renyi_Divergence_CC_rescaled.eval_var_formula"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_tf.Renyi_Divergence_CC_rescaled.eval_var_formula" title="Link to this definition"></a></dt>
<dd><p>Evaluates the variational formula for the rescaled Renyi divergence.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Samples from distribution P.</p></li>
<li><p><strong>y</strong> – Samples from distribution Q.</p></li>
<li><p><strong>labels</strong> – Optional labels for the input data.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Rescaled Renyi divergence loss.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_tf.Renyi_Divergence_CC_rescaled.eval_var_formula_gen">
<span class="sig-name descname"><span class="pre">eval_var_formula_gen</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_tf.html#Renyi_Divergence_CC_rescaled.eval_var_formula_gen"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_tf.Renyi_Divergence_CC_rescaled.eval_var_formula_gen" title="Link to this definition"></a></dt>
<dd><p>Evaluates the generator’s objective based on rescaled Renyi divergence.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_tf.Renyi_Divergence_CC_rescaled.final_layer_activation">
<span class="sig-name descname"><span class="pre">final_layer_activation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_tf.html#Renyi_Divergence_CC_rescaled.final_layer_activation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_tf.Renyi_Divergence_CC_rescaled.final_layer_activation" title="Link to this definition"></a></dt>
<dd><p>Applies the final layer activation and scales it by alpha.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="Divergences_tf.Renyi_Divergence_DV">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">Divergences_tf.</span></span><span class="sig-name descname"><span class="pre">Renyi_Divergence_DV</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_tf.html#Renyi_Divergence_DV"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_tf.Renyi_Divergence_DV" title="Link to this definition"></a></dt>
<dd><p>Renyi divergence class based on the Renyi-Donsker-Varadhan variational formula.
R_alpha(P||Q), x~P, y~Q.</p>
<dl class="py method">
<dt class="sig sig-object py" id="Divergences_tf.Renyi_Divergence_DV.eval_var_formula">
<span class="sig-name descname"><span class="pre">eval_var_formula</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_tf.html#Renyi_Divergence_DV.eval_var_formula"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_tf.Renyi_Divergence_DV.eval_var_formula" title="Link to this definition"></a></dt>
<dd><p>Evaluates the variational formula for Renyi divergence based on the Renyi-Donsker-Varadhan formula.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Samples from distribution P.</p></li>
<li><p><strong>y</strong> – Samples from distribution Q.</p></li>
<li><p><strong>labels</strong> – Optional labels for the input data.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Renyi divergence loss.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_tf.Renyi_Divergence_DV.eval_var_formula_gen">
<span class="sig-name descname"><span class="pre">eval_var_formula_gen</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_tf.html#Renyi_Divergence_DV.eval_var_formula_gen"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_tf.Renyi_Divergence_DV.eval_var_formula_gen" title="Link to this definition"></a></dt>
<dd><p>Evaluates the generator’s objective based on Renyi divergence.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="Divergences_tf.Renyi_Divergence_WCR">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">Divergences_tf.</span></span><span class="sig-name descname"><span class="pre">Renyi_Divergence_WCR</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_tf.html#Renyi_Divergence_WCR"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_tf.Renyi_Divergence_WCR" title="Link to this definition"></a></dt>
<dd><p>Renyi divergence class as alpha approaches infinity (worst-case regret divergence).
Dinfty(P||Q), where x ~ P and y ~ Q.</p>
<dl class="py method">
<dt class="sig sig-object py" id="Divergences_tf.Renyi_Divergence_WCR.eval_var_formula">
<span class="sig-name descname"><span class="pre">eval_var_formula</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_tf.html#Renyi_Divergence_WCR.eval_var_formula"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_tf.Renyi_Divergence_WCR.eval_var_formula" title="Link to this definition"></a></dt>
<dd><p>Evaluates the variational formula for worst-case regret divergence as alpha approaches infinity.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>tf.Tensor</em>) – Samples from distribution P.</p></li>
<li><p><strong>y</strong> (<em>tf.Tensor</em>) – Samples from distribution Q.</p></li>
<li><p><strong>labels</strong> (<em>tf.Tensor</em><em>, </em><em>optional</em>) – Optional labels for the input data.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Worst-case regret divergence loss.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tf.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_tf.Renyi_Divergence_WCR.eval_var_formula_gen">
<span class="sig-name descname"><span class="pre">eval_var_formula_gen</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_tf.html#Renyi_Divergence_WCR.eval_var_formula_gen"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_tf.Renyi_Divergence_WCR.eval_var_formula_gen" title="Link to this definition"></a></dt>
<dd><p>Evaluates the generator’s objective based on worst-case regret divergence.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>tf.Tensor</em>) – Samples from distribution Q.</p></li>
<li><p><strong>labels</strong> (<em>tf.Tensor</em><em>, </em><em>optional</em>) – Optional labels for the input data.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Generator’s loss based on worst-case regret divergence.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tf.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="Divergences_tf.alpha_Divergence_LT">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">Divergences_tf.</span></span><span class="sig-name descname"><span class="pre">alpha_Divergence_LT</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_tf.html#alpha_Divergence_LT"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_tf.alpha_Divergence_LT" title="Link to this definition"></a></dt>
<dd><p>Alpha-divergence class based on the Legendre transform.
D_{f_alpha}(P||Q), x~P, y~Q.</p>
<dl class="py method">
<dt class="sig sig-object py" id="Divergences_tf.alpha_Divergence_LT.f_star">
<span class="sig-name descname"><span class="pre">f_star</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_tf.html#alpha_Divergence_LT.f_star"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_tf.alpha_Divergence_LT.f_star" title="Link to this definition"></a></dt>
<dd><p>Legendre transform of f_alpha based on the alpha value.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_tf.alpha_Divergence_LT.get_order">
<span class="sig-name descname"><span class="pre">get_order</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_tf.html#alpha_Divergence_LT.get_order"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_tf.alpha_Divergence_LT.get_order" title="Link to this definition"></a></dt>
<dd><p>Returns the order of the alpha-divergence.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_tf.alpha_Divergence_LT.set_order">
<span class="sig-name descname"><span class="pre">set_order</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">alpha</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_tf.html#alpha_Divergence_LT.set_order"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_tf.alpha_Divergence_LT.set_order" title="Link to this definition"></a></dt>
<dd><p>Sets the order of the alpha-divergence.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="Divergences_tf.f_Divergence">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">Divergences_tf.</span></span><span class="sig-name descname"><span class="pre">f_Divergence</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_tf.html#f_Divergence"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_tf.f_Divergence" title="Link to this definition"></a></dt>
<dd><p>f-divergence class, parent class for f-divergence-based measures D_f(P||Q).
Subclasses must implement the Legendre transform f_star.</p>
<dl class="py method">
<dt class="sig sig-object py" id="Divergences_tf.f_Divergence.eval_var_formula">
<span class="sig-name descname"><span class="pre">eval_var_formula</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_tf.html#f_Divergence.eval_var_formula"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_tf.f_Divergence.eval_var_formula" title="Link to this definition"></a></dt>
<dd><p>Evaluates the variational formula for f-divergence.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Samples from distribution P.</p></li>
<li><p><strong>y</strong> – Samples from distribution Q.</p></li>
<li><p><strong>labels</strong> – Optional labels for the input data.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>f-divergence loss.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_tf.f_Divergence.eval_var_formula_gen">
<span class="sig-name descname"><span class="pre">eval_var_formula_gen</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_tf.html#f_Divergence.eval_var_formula_gen"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_tf.f_Divergence.eval_var_formula_gen" title="Link to this definition"></a></dt>
<dd><p>Evaluates the variational formula for f-divergence applied to the generator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Generated samples.</p></li>
<li><p><strong>labels</strong> – Optional labels for the input data.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Generator loss based on f-divergence.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_tf.f_Divergence.f_star">
<span class="sig-name descname"><span class="pre">f_star</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_tf.html#f_Divergence.f_star"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_tf.f_Divergence.f_star" title="Link to this definition"></a></dt>
<dd><p>Placeholder for the Legendre transform of f. Should be implemented by subclasses.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_tf.f_Divergence.final_layer_activation">
<span class="sig-name descname"><span class="pre">final_layer_activation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_tf.html#f_Divergence.final_layer_activation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_tf.f_Divergence.final_layer_activation" title="Link to this definition"></a></dt>
<dd><p>Applies the final layer activation.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="Divergences_tf.squared_Hellinger_LT">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">Divergences_tf.</span></span><span class="sig-name descname"><span class="pre">squared_Hellinger_LT</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_tf.html#squared_Hellinger_LT"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_tf.squared_Hellinger_LT" title="Link to this definition"></a></dt>
<dd><p>Squared Hellinger distance class based on the Legendre transform.
H(P||Q), x~P, y~Q.</p>
<dl class="py method">
<dt class="sig sig-object py" id="Divergences_tf.squared_Hellinger_LT.f_star">
<span class="sig-name descname"><span class="pre">f_star</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_tf.html#squared_Hellinger_LT.f_star"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_tf.squared_Hellinger_LT.f_star" title="Link to this definition"></a></dt>
<dd><p>Legendre transform of f(y) = (sqrt(y) - 1)^2.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_tf.squared_Hellinger_LT.final_layer_activation">
<span class="sig-name descname"><span class="pre">final_layer_activation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_tf.html#squared_Hellinger_LT.final_layer_activation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_tf.squared_Hellinger_LT.final_layer_activation" title="Link to this definition"></a></dt>
<dd><p>Applies the final layer activation for squared Hellinger distance.</p>
</dd></dl>

</dd></dl>

<dl class="py class" id="module-Divergences_torch">
<dt class="sig sig-object py" id="Divergences_torch.Discriminator_Penalty">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">Divergences_torch.</span></span><span class="sig-name descname"><span class="pre">Discriminator_Penalty</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">penalty_weight</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_torch.html#Discriminator_Penalty"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_torch.Discriminator_Penalty" title="Link to this definition"></a></dt>
<dd><p>Discriminator penalty class penalizes the divergence objective functional during training.
Allows for the (approximate) implementation of discriminator constraints.</p>
<dl class="py method">
<dt class="sig sig-object py" id="Divergences_torch.Discriminator_Penalty.evaluate">
<span class="sig-name descname"><span class="pre">evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">discriminator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_torch.html#Discriminator_Penalty.evaluate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_torch.Discriminator_Penalty.evaluate" title="Link to this definition"></a></dt>
<dd><p>Evaluates the penalty term. Should be overridden by subclasses.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>discriminator</strong> – Discriminator model.</p></li>
<li><p><strong>x</strong> – Samples from distribution P.</p></li>
<li><p><strong>y</strong> – Samples from distribution Q.</p></li>
<li><p><strong>labels</strong> – Optional labels for the input data.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>None. (Subclasses should implement penalty evaluation.)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_torch.Discriminator_Penalty.get_penalty_weight">
<span class="sig-name descname"><span class="pre">get_penalty_weight</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_torch.html#Discriminator_Penalty.get_penalty_weight"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_torch.Discriminator_Penalty.get_penalty_weight" title="Link to this definition"></a></dt>
<dd><p>Returns the weight of the penalty term.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_torch.Discriminator_Penalty.set_penalty_weight">
<span class="sig-name descname"><span class="pre">set_penalty_weight</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">weight</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_torch.html#Discriminator_Penalty.set_penalty_weight"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_torch.Discriminator_Penalty.set_penalty_weight" title="Link to this definition"></a></dt>
<dd><p>Sets the weight of the penalty term.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="Divergences_torch.Divergence">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">Divergences_torch.</span></span><span class="sig-name descname"><span class="pre">Divergence</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">discriminator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">disc_optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">discriminator_penalty</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_torch.html#Divergence"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_torch.Divergence" title="Link to this definition"></a></dt>
<dd><p>Divergence D(P||Q) between random variables x~P, y~Q.
Parent class where common parameters and functions are defined.</p>
<dl class="py method">
<dt class="sig sig-object py" id="Divergences_torch.Divergence.discriminate">
<span class="sig-name descname"><span class="pre">discriminate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_torch.html#Divergence.discriminate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_torch.Divergence.discriminate" title="Link to this definition"></a></dt>
<dd><p>Discriminates between samples from distributions P and Q.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Input data to discriminate.</p></li>
<li><p><strong>labels</strong> – Optional labels for the input data.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Discriminator output.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_torch.Divergence.discriminator_loss">
<span class="sig-name descname"><span class="pre">discriminator_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_torch.html#Divergence.discriminator_loss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_torch.Divergence.discriminator_loss" title="Link to this definition"></a></dt>
<dd><p>Computes the discriminator loss.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Samples from distribution P.</p></li>
<li><p><strong>y</strong> – Samples from distribution Q.</p></li>
<li><p><strong>labels</strong> – Optional labels for the input data.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Discriminator loss.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_torch.Divergence.estimate">
<span class="sig-name descname"><span class="pre">estimate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_torch.html#Divergence.estimate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_torch.Divergence.estimate" title="Link to this definition"></a></dt>
<dd><p>Estimates the divergence measure.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Samples from distribution P.</p></li>
<li><p><strong>y</strong> – Samples from distribution Q.</p></li>
<li><p><strong>labels</strong> – Optional labels for the input data.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Estimated divergence loss.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_torch.Divergence.eval_var_formula">
<span class="sig-name descname"><span class="pre">eval_var_formula</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_torch.html#Divergence.eval_var_formula"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_torch.Divergence.eval_var_formula" title="Link to this definition"></a></dt>
<dd><p>Evaluates the variational formula for the divergence measure.
Should be implemented by subclasses.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Samples from distribution P.</p></li>
<li><p><strong>y</strong> – Samples from distribution Q.</p></li>
<li><p><strong>labels</strong> – Optional labels for the input data.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>None (to be overridden by subclasses).</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_torch.Divergence.generator_loss">
<span class="sig-name descname"><span class="pre">generator_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_torch.html#Divergence.generator_loss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_torch.Divergence.generator_loss" title="Link to this definition"></a></dt>
<dd><p>Computes the generator loss.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Generated samples.</p></li>
<li><p><strong>labels</strong> – Optional labels for the input data.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Generator loss.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_torch.Divergence.get_batch_size">
<span class="sig-name descname"><span class="pre">get_batch_size</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_torch.html#Divergence.get_batch_size"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_torch.Divergence.get_batch_size" title="Link to this definition"></a></dt>
<dd><p>Returns the batch size.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_torch.Divergence.get_discriminator">
<span class="sig-name descname"><span class="pre">get_discriminator</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_torch.html#Divergence.get_discriminator"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_torch.Divergence.get_discriminator" title="Link to this definition"></a></dt>
<dd><p>Returns the discriminator model.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_torch.Divergence.get_learning_rate">
<span class="sig-name descname"><span class="pre">get_learning_rate</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_torch.html#Divergence.get_learning_rate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_torch.Divergence.get_learning_rate" title="Link to this definition"></a></dt>
<dd><p>Returns the learning rate.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_torch.Divergence.get_no_epochs">
<span class="sig-name descname"><span class="pre">get_no_epochs</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_torch.html#Divergence.get_no_epochs"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_torch.Divergence.get_no_epochs" title="Link to this definition"></a></dt>
<dd><p>Returns the number of training epochs.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_torch.Divergence.set_batch_size">
<span class="sig-name descname"><span class="pre">set_batch_size</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">BATCH_SIZE</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_torch.html#Divergence.set_batch_size"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_torch.Divergence.set_batch_size" title="Link to this definition"></a></dt>
<dd><p>Sets the batch size.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_torch.Divergence.set_discriminator">
<span class="sig-name descname"><span class="pre">set_discriminator</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">discriminator</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_torch.html#Divergence.set_discriminator"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_torch.Divergence.set_discriminator" title="Link to this definition"></a></dt>
<dd><p>Sets a new discriminator model.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_torch.Divergence.set_learning_rate">
<span class="sig-name descname"><span class="pre">set_learning_rate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">lr</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_torch.html#Divergence.set_learning_rate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_torch.Divergence.set_learning_rate" title="Link to this definition"></a></dt>
<dd><p>Sets the learning rate.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_torch.Divergence.set_no_epochs">
<span class="sig-name descname"><span class="pre">set_no_epochs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">epochs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_torch.html#Divergence.set_no_epochs"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_torch.Divergence.set_no_epochs" title="Link to this definition"></a></dt>
<dd><p>Sets the number of training epochs.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_torch.Divergence.train">
<span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_P</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_Q</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_estimates</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_torch.html#Divergence.train"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_torch.Divergence.train" title="Link to this definition"></a></dt>
<dd><p>Trains the model for a number of epochs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data_P</strong> – Data samples from distribution P.</p></li>
<li><p><strong>data_Q</strong> – Data samples from distribution Q.</p></li>
<li><p><strong>labels</strong> – Optional labels for the input data.</p></li>
<li><p><strong>save_estimates</strong> – Whether to save divergence estimates.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A list of divergence estimates for each epoch.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_torch.Divergence.train_step">
<span class="sig-name descname"><span class="pre">train_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_torch.html#Divergence.train_step"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_torch.Divergence.train_step" title="Link to this definition"></a></dt>
<dd><p>Performs a training step for the discriminator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Samples from distribution P.</p></li>
<li><p><strong>y</strong> – Samples from distribution Q.</p></li>
<li><p><strong>labels</strong> – Optional labels for the input data.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Loss value for the current step.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="Divergences_torch.Gradient_Penalty_1Sided">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">Divergences_torch.</span></span><span class="sig-name descname"><span class="pre">Gradient_Penalty_1Sided</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">penalty_weight</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Lip_const</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_torch.html#Gradient_Penalty_1Sided"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_torch.Gradient_Penalty_1Sided" title="Link to this definition"></a></dt>
<dd><p>One-sided gradient penalty class to enforce the Lipschitz constant &lt;= Lip_const.</p>
<dl class="py method">
<dt class="sig sig-object py" id="Divergences_torch.Gradient_Penalty_1Sided.evaluate">
<span class="sig-name descname"><span class="pre">evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">discriminator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_torch.html#Gradient_Penalty_1Sided.evaluate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_torch.Gradient_Penalty_1Sided.evaluate" title="Link to this definition"></a></dt>
<dd><p>Computes the one-sided gradient penalty to enforce the Lipschitz constant &lt;= Lip_const.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>discriminator</strong> – Discriminator model.</p></li>
<li><p><strong>x</strong> – Samples from distribution P.</p></li>
<li><p><strong>y</strong> – Samples from distribution Q.</p></li>
<li><p><strong>labels</strong> – Optional labels for the input data.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>One-sided gradient penalty value.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_torch.Gradient_Penalty_1Sided.get_Lip_constant">
<span class="sig-name descname"><span class="pre">get_Lip_constant</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_torch.html#Gradient_Penalty_1Sided.get_Lip_constant"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_torch.Gradient_Penalty_1Sided.get_Lip_constant" title="Link to this definition"></a></dt>
<dd><p>Returns the target Lipschitz constant.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_torch.Gradient_Penalty_1Sided.set_Lip_constant">
<span class="sig-name descname"><span class="pre">set_Lip_constant</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">L</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_torch.html#Gradient_Penalty_1Sided.set_Lip_constant"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_torch.Gradient_Penalty_1Sided.set_Lip_constant" title="Link to this definition"></a></dt>
<dd><p>Sets the target Lipschitz constant.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="Divergences_torch.Gradient_Penalty_2Sided">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">Divergences_torch.</span></span><span class="sig-name descname"><span class="pre">Gradient_Penalty_2Sided</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">penalty_weight</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Lip_const</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_torch.html#Gradient_Penalty_2Sided"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_torch.Gradient_Penalty_2Sided" title="Link to this definition"></a></dt>
<dd><p>Two-sided gradient penalty class to enforce the Lipschitz constant = Lip_const.</p>
<dl class="py method">
<dt class="sig sig-object py" id="Divergences_torch.Gradient_Penalty_2Sided.evaluate">
<span class="sig-name descname"><span class="pre">evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">discriminator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_torch.html#Gradient_Penalty_2Sided.evaluate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_torch.Gradient_Penalty_2Sided.evaluate" title="Link to this definition"></a></dt>
<dd><p>Computes the two-sided gradient penalty to enforce the Lipschitz constant = Lip_const.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>discriminator</strong> – Discriminator model.</p></li>
<li><p><strong>x</strong> – Samples from distribution P.</p></li>
<li><p><strong>y</strong> – Samples from distribution Q.</p></li>
<li><p><strong>labels</strong> – Optional labels for the input data.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Two-sided gradient penalty value.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_torch.Gradient_Penalty_2Sided.get_Lip_constant">
<span class="sig-name descname"><span class="pre">get_Lip_constant</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_torch.html#Gradient_Penalty_2Sided.get_Lip_constant"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_torch.Gradient_Penalty_2Sided.get_Lip_constant" title="Link to this definition"></a></dt>
<dd><p>Returns the target Lipschitz constant.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_torch.Gradient_Penalty_2Sided.set_Lip_constant">
<span class="sig-name descname"><span class="pre">set_Lip_constant</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">L</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_torch.html#Gradient_Penalty_2Sided.set_Lip_constant"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_torch.Gradient_Penalty_2Sided.set_Lip_constant" title="Link to this definition"></a></dt>
<dd><p>Sets the target Lipschitz constant.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="Divergences_torch.IPM">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">Divergences_torch.</span></span><span class="sig-name descname"><span class="pre">IPM</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">discriminator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">disc_optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">discriminator_penalty</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_torch.html#IPM"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_torch.IPM" title="Link to this definition"></a></dt>
<dd><p>IPM class for evaluating Integral Probability Metrics (IPM).</p>
<dl class="py method">
<dt class="sig sig-object py" id="Divergences_torch.IPM.eval_var_formula">
<span class="sig-name descname"><span class="pre">eval_var_formula</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_torch.html#IPM.eval_var_formula"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_torch.IPM.eval_var_formula" title="Link to this definition"></a></dt>
<dd><p>Evaluates the variational formula for IPM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Samples from distribution P.</p></li>
<li><p><strong>y</strong> – Samples from distribution Q.</p></li>
<li><p><strong>labels</strong> – Optional labels for the input data.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>IPM loss.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_torch.IPM.eval_var_formula_gen">
<span class="sig-name descname"><span class="pre">eval_var_formula_gen</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_torch.html#IPM.eval_var_formula_gen"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_torch.IPM.eval_var_formula_gen" title="Link to this definition"></a></dt>
<dd><p>Evaluates the variational formula for IPM applied to the generator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Generated samples.</p></li>
<li><p><strong>labels</strong> – Optional labels for the input data.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Generator loss based on IPM.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="Divergences_torch.Jensen_Shannon_LT">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">Divergences_torch.</span></span><span class="sig-name descname"><span class="pre">Jensen_Shannon_LT</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">discriminator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">disc_optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">discriminator_penalty</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_torch.html#Jensen_Shannon_LT"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_torch.Jensen_Shannon_LT" title="Link to this definition"></a></dt>
<dd><p>Jensen-Shannon divergence class based on the Legendre transform.
JS(P||Q), x~P, y~Q.</p>
<dl class="py method">
<dt class="sig sig-object py" id="Divergences_torch.Jensen_Shannon_LT.f_star">
<span class="sig-name descname"><span class="pre">f_star</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_torch.html#Jensen_Shannon_LT.f_star"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_torch.Jensen_Shannon_LT.f_star" title="Link to this definition"></a></dt>
<dd><p>Legendre transform of f(y) = y * log(y) - (y + 1) * log((y + 1) / 2).</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_torch.Jensen_Shannon_LT.final_layer_activation">
<span class="sig-name descname"><span class="pre">final_layer_activation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_torch.html#Jensen_Shannon_LT.final_layer_activation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_torch.Jensen_Shannon_LT.final_layer_activation" title="Link to this definition"></a></dt>
<dd><p>Applies the final layer activation for Jensen-Shannon divergence.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="Divergences_torch.KLD_DV">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">Divergences_torch.</span></span><span class="sig-name descname"><span class="pre">KLD_DV</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">discriminator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">disc_optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">discriminator_penalty</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_torch.html#KLD_DV"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_torch.KLD_DV" title="Link to this definition"></a></dt>
<dd><p>KL divergence class based on the Donsker-Varadhan variational formula.
KL(P||Q), x~P, y~Q.</p>
<dl class="py method">
<dt class="sig sig-object py" id="Divergences_torch.KLD_DV.eval_var_formula">
<span class="sig-name descname"><span class="pre">eval_var_formula</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_torch.html#KLD_DV.eval_var_formula"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_torch.KLD_DV.eval_var_formula" title="Link to this definition"></a></dt>
<dd><p>Evaluates the variational formula for KL divergence.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Samples from distribution P.</p></li>
<li><p><strong>y</strong> – Samples from distribution Q.</p></li>
<li><p><strong>labels</strong> – Optional labels for the input data.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>KL divergence loss.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_torch.KLD_DV.eval_var_formula_gen">
<span class="sig-name descname"><span class="pre">eval_var_formula_gen</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_torch.html#KLD_DV.eval_var_formula_gen"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_torch.KLD_DV.eval_var_formula_gen" title="Link to this definition"></a></dt>
<dd><p>Evaluates the generator’s objective based on KL divergence.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="Divergences_torch.KLD_LT">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">Divergences_torch.</span></span><span class="sig-name descname"><span class="pre">KLD_LT</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">discriminator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">disc_optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">discriminator_penalty</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_torch.html#KLD_LT"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_torch.KLD_LT" title="Link to this definition"></a></dt>
<dd><p>Kullback-Leibler (KL) divergence class based on the Legendre transform.
KL(P||Q), x~P, y~Q.</p>
<dl class="py method">
<dt class="sig sig-object py" id="Divergences_torch.KLD_LT.f_star">
<span class="sig-name descname"><span class="pre">f_star</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_torch.html#KLD_LT.f_star"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_torch.KLD_LT.f_star" title="Link to this definition"></a></dt>
<dd><p>Legendre transform of f(y) = y * log(y).</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="Divergences_torch.Pearson_chi_squared_HCR">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">Divergences_torch.</span></span><span class="sig-name descname"><span class="pre">Pearson_chi_squared_HCR</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">discriminator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">disc_optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">discriminator_penalty</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_torch.html#Pearson_chi_squared_HCR"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_torch.Pearson_chi_squared_HCR" title="Link to this definition"></a></dt>
<dd><p>Pearson chi-squared divergence class based on the Hammersley-Chapman-Robbins bound.
chi^2(P||Q), x~P, y~Q.</p>
<dl class="py method">
<dt class="sig sig-object py" id="Divergences_torch.Pearson_chi_squared_HCR.eval_var_formula">
<span class="sig-name descname"><span class="pre">eval_var_formula</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_torch.html#Pearson_chi_squared_HCR.eval_var_formula"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_torch.Pearson_chi_squared_HCR.eval_var_formula" title="Link to this definition"></a></dt>
<dd><p>Evaluates the variational formula for Pearson chi-squared divergence based on the Hammersley-Chapman-Robbins bound.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Samples from distribution P.</p></li>
<li><p><strong>y</strong> – Samples from distribution Q.</p></li>
<li><p><strong>labels</strong> – Optional labels for the input data.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Pearson chi-squared divergence loss.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_torch.Pearson_chi_squared_HCR.eval_var_formula_gen">
<span class="sig-name descname"><span class="pre">eval_var_formula_gen</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_torch.html#Pearson_chi_squared_HCR.eval_var_formula_gen"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_torch.Pearson_chi_squared_HCR.eval_var_formula_gen" title="Link to this definition"></a></dt>
<dd><p>Evaluates the generator’s objective based on Pearson chi-squared divergence.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="Divergences_torch.Pearson_chi_squared_LT">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">Divergences_torch.</span></span><span class="sig-name descname"><span class="pre">Pearson_chi_squared_LT</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">discriminator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">disc_optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">discriminator_penalty</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_torch.html#Pearson_chi_squared_LT"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_torch.Pearson_chi_squared_LT" title="Link to this definition"></a></dt>
<dd><p>Pearson chi-squared divergence class based on the Legendre transform.
chi^2(P||Q), x~P, y~Q.</p>
<dl class="py method">
<dt class="sig sig-object py" id="Divergences_torch.Pearson_chi_squared_LT.f_star">
<span class="sig-name descname"><span class="pre">f_star</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_torch.html#Pearson_chi_squared_LT.f_star"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_torch.Pearson_chi_squared_LT.f_star" title="Link to this definition"></a></dt>
<dd><p>Legendre transform of f(y) = (y - 1)^2.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="Divergences_torch.Renyi_Divergence">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">Divergences_torch.</span></span><span class="sig-name descname"><span class="pre">Renyi_Divergence</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">discriminator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">disc_optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">discriminator_penalty</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_torch.html#Renyi_Divergence"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_torch.Renyi_Divergence" title="Link to this definition"></a></dt>
<dd><p>Renyi divergence class for computing Renyi divergence R_alpha(P||Q), x~P, y~Q.</p>
<dl class="py method">
<dt class="sig sig-object py" id="Divergences_torch.Renyi_Divergence.get_order">
<span class="sig-name descname"><span class="pre">get_order</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_torch.html#Renyi_Divergence.get_order"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_torch.Renyi_Divergence.get_order" title="Link to this definition"></a></dt>
<dd><p>Returns the order of the Renyi divergence.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_torch.Renyi_Divergence.set_order">
<span class="sig-name descname"><span class="pre">set_order</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">alpha</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_torch.html#Renyi_Divergence.set_order"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_torch.Renyi_Divergence.set_order" title="Link to this definition"></a></dt>
<dd><p>Sets the order of the Renyi divergence.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="Divergences_torch.Renyi_Divergence_CC">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">Divergences_torch.</span></span><span class="sig-name descname"><span class="pre">Renyi_Divergence_CC</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">discriminator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">disc_optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fl_act_func</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">discriminator_penalty</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_torch.html#Renyi_Divergence_CC"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_torch.Renyi_Divergence_CC" title="Link to this definition"></a></dt>
<dd><p>Renyi divergence class based on the convex-conjugate variational formula.
R_alpha(P||Q), x~P, y~Q.</p>
<dl class="py method">
<dt class="sig sig-object py" id="Divergences_torch.Renyi_Divergence_CC.eval_var_formula">
<span class="sig-name descname"><span class="pre">eval_var_formula</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_torch.html#Renyi_Divergence_CC.eval_var_formula"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_torch.Renyi_Divergence_CC.eval_var_formula" title="Link to this definition"></a></dt>
<dd><p>Evaluates the variational formula for Renyi divergence based on the convex-conjugate formula.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Samples from distribution P.</p></li>
<li><p><strong>y</strong> – Samples from distribution Q.</p></li>
<li><p><strong>labels</strong> – Optional labels for the input data.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Renyi divergence loss.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_torch.Renyi_Divergence_CC.eval_var_formula_gen">
<span class="sig-name descname"><span class="pre">eval_var_formula_gen</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_torch.html#Renyi_Divergence_CC.eval_var_formula_gen"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_torch.Renyi_Divergence_CC.eval_var_formula_gen" title="Link to this definition"></a></dt>
<dd><p>Evaluates the generator’s objective based on Renyi divergence using the convex-conjugate formula.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_torch.Renyi_Divergence_CC.final_layer_activation">
<span class="sig-name descname"><span class="pre">final_layer_activation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_torch.html#Renyi_Divergence_CC.final_layer_activation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_torch.Renyi_Divergence_CC.final_layer_activation" title="Link to this definition"></a></dt>
<dd><p>Applies the final layer activation to enforce positive values.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="Divergences_torch.Renyi_Divergence_CC_rescaled">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">Divergences_torch.</span></span><span class="sig-name descname"><span class="pre">Renyi_Divergence_CC_rescaled</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">discriminator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">disc_optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fl_act_func</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">discriminator_penalty</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_torch.html#Renyi_Divergence_CC_rescaled"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_torch.Renyi_Divergence_CC_rescaled" title="Link to this definition"></a></dt>
<dd><p>Rescaled Renyi divergence class based on the rescaled convex-conjugate variational formula.
alpha * R_alpha(P||Q), x~P, y~Q.</p>
<dl class="py method">
<dt class="sig sig-object py" id="Divergences_torch.Renyi_Divergence_CC_rescaled.eval_var_formula">
<span class="sig-name descname"><span class="pre">eval_var_formula</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_torch.html#Renyi_Divergence_CC_rescaled.eval_var_formula"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_torch.Renyi_Divergence_CC_rescaled.eval_var_formula" title="Link to this definition"></a></dt>
<dd><p>Evaluates the variational formula for the rescaled Renyi divergence.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Samples from distribution P.</p></li>
<li><p><strong>y</strong> – Samples from distribution Q.</p></li>
<li><p><strong>labels</strong> – Optional labels for the input data.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Rescaled Renyi divergence loss.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_torch.Renyi_Divergence_CC_rescaled.eval_var_formula_gen">
<span class="sig-name descname"><span class="pre">eval_var_formula_gen</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_torch.html#Renyi_Divergence_CC_rescaled.eval_var_formula_gen"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_torch.Renyi_Divergence_CC_rescaled.eval_var_formula_gen" title="Link to this definition"></a></dt>
<dd><p>Evaluates the generator’s objective based on rescaled Renyi divergence.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_torch.Renyi_Divergence_CC_rescaled.final_layer_activation">
<span class="sig-name descname"><span class="pre">final_layer_activation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_torch.html#Renyi_Divergence_CC_rescaled.final_layer_activation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_torch.Renyi_Divergence_CC_rescaled.final_layer_activation" title="Link to this definition"></a></dt>
<dd><p>Applies the final layer activation and scales it by alpha.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="Divergences_torch.Renyi_Divergence_DV">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">Divergences_torch.</span></span><span class="sig-name descname"><span class="pre">Renyi_Divergence_DV</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">discriminator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">disc_optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">discriminator_penalty</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_torch.html#Renyi_Divergence_DV"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_torch.Renyi_Divergence_DV" title="Link to this definition"></a></dt>
<dd><p>Renyi divergence class based on the Renyi-Donsker-Varadhan variational formula.
R_alpha(P||Q), x~P, y~Q.</p>
<dl class="py method">
<dt class="sig sig-object py" id="Divergences_torch.Renyi_Divergence_DV.eval_var_formula">
<span class="sig-name descname"><span class="pre">eval_var_formula</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_torch.html#Renyi_Divergence_DV.eval_var_formula"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_torch.Renyi_Divergence_DV.eval_var_formula" title="Link to this definition"></a></dt>
<dd><p>Evaluates the variational formula for Renyi divergence based on the Renyi-Donsker-Varadhan formula.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Samples from distribution P.</p></li>
<li><p><strong>y</strong> – Samples from distribution Q.</p></li>
<li><p><strong>labels</strong> – Optional labels for the input data.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Renyi divergence loss.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_torch.Renyi_Divergence_DV.eval_var_formula_gen">
<span class="sig-name descname"><span class="pre">eval_var_formula_gen</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_torch.html#Renyi_Divergence_DV.eval_var_formula_gen"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_torch.Renyi_Divergence_DV.eval_var_formula_gen" title="Link to this definition"></a></dt>
<dd><p>Evaluates the generator’s objective based on Renyi divergence.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="Divergences_torch.Renyi_Divergence_WCR">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">Divergences_torch.</span></span><span class="sig-name descname"><span class="pre">Renyi_Divergence_WCR</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">discriminator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">disc_optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fl_act_func</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">discriminator_penalty</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_torch.html#Renyi_Divergence_WCR"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_torch.Renyi_Divergence_WCR" title="Link to this definition"></a></dt>
<dd><p>Renyi divergence class as alpha approaches infinity (worst-case regret divergence).
Dinfty(P||Q), x~P, y~Q.</p>
<dl class="py method">
<dt class="sig sig-object py" id="Divergences_torch.Renyi_Divergence_WCR.eval_var_formula">
<span class="sig-name descname"><span class="pre">eval_var_formula</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_torch.html#Renyi_Divergence_WCR.eval_var_formula"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_torch.Renyi_Divergence_WCR.eval_var_formula" title="Link to this definition"></a></dt>
<dd><p>Evaluates the variational formula for worst-case regret divergence as alpha approaches infinity.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Samples from distribution P.</p></li>
<li><p><strong>y</strong> – Samples from distribution Q.</p></li>
<li><p><strong>labels</strong> – Optional labels for the input data.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Worst-case regret divergence loss.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_torch.Renyi_Divergence_WCR.eval_var_formula_gen">
<span class="sig-name descname"><span class="pre">eval_var_formula_gen</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_torch.html#Renyi_Divergence_WCR.eval_var_formula_gen"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_torch.Renyi_Divergence_WCR.eval_var_formula_gen" title="Link to this definition"></a></dt>
<dd><p>Evaluates the generator’s objective based on worst-case regret divergence.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="Divergences_torch.alpha_Divergence_LT">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">Divergences_torch.</span></span><span class="sig-name descname"><span class="pre">alpha_Divergence_LT</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">discriminator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">disc_optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">discriminator_penalty</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_torch.html#alpha_Divergence_LT"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_torch.alpha_Divergence_LT" title="Link to this definition"></a></dt>
<dd><p>Alpha-divergence class based on the Legendre transform.
D_{f_alpha}(P||Q), x~P, y~Q.</p>
<dl class="py method">
<dt class="sig sig-object py" id="Divergences_torch.alpha_Divergence_LT.f_star">
<span class="sig-name descname"><span class="pre">f_star</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_torch.html#alpha_Divergence_LT.f_star"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_torch.alpha_Divergence_LT.f_star" title="Link to this definition"></a></dt>
<dd><p>Legendre transform of f_alpha based on the alpha value.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_torch.alpha_Divergence_LT.get_order">
<span class="sig-name descname"><span class="pre">get_order</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_torch.html#alpha_Divergence_LT.get_order"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_torch.alpha_Divergence_LT.get_order" title="Link to this definition"></a></dt>
<dd><p>Returns the order of the alpha-divergence.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_torch.alpha_Divergence_LT.set_order">
<span class="sig-name descname"><span class="pre">set_order</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">alpha</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_torch.html#alpha_Divergence_LT.set_order"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_torch.alpha_Divergence_LT.set_order" title="Link to this definition"></a></dt>
<dd><p>Sets the order of the alpha-divergence.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="Divergences_torch.f_Divergence">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">Divergences_torch.</span></span><span class="sig-name descname"><span class="pre">f_Divergence</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">discriminator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">disc_optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">discriminator_penalty</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_torch.html#f_Divergence"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_torch.f_Divergence" title="Link to this definition"></a></dt>
<dd><p>f-divergence class, parent class for f-divergence-based measures D_f(P||Q).
Subclasses must implement the Legendre transform f_star.</p>
<dl class="py method">
<dt class="sig sig-object py" id="Divergences_torch.f_Divergence.eval_var_formula">
<span class="sig-name descname"><span class="pre">eval_var_formula</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_torch.html#f_Divergence.eval_var_formula"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_torch.f_Divergence.eval_var_formula" title="Link to this definition"></a></dt>
<dd><p>Evaluates the variational formula for f-divergence.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Samples from distribution P.</p></li>
<li><p><strong>y</strong> – Samples from distribution Q.</p></li>
<li><p><strong>labels</strong> – Optional labels for the input data.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>f-divergence loss.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_torch.f_Divergence.eval_var_formula_gen">
<span class="sig-name descname"><span class="pre">eval_var_formula_gen</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_torch.html#f_Divergence.eval_var_formula_gen"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_torch.f_Divergence.eval_var_formula_gen" title="Link to this definition"></a></dt>
<dd><p>Evaluates the variational formula for f-divergence applied to the generator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Generated samples.</p></li>
<li><p><strong>labels</strong> – Optional labels for the input data.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Generator loss based on f-divergence.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_torch.f_Divergence.f_star">
<span class="sig-name descname"><span class="pre">f_star</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_torch.html#f_Divergence.f_star"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_torch.f_Divergence.f_star" title="Link to this definition"></a></dt>
<dd><p>Placeholder for the Legendre transform of f. Should be implemented by subclasses.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_torch.f_Divergence.final_layer_activation">
<span class="sig-name descname"><span class="pre">final_layer_activation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_torch.html#f_Divergence.final_layer_activation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_torch.f_Divergence.final_layer_activation" title="Link to this definition"></a></dt>
<dd><p>Applies the final layer activation.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="Divergences_torch.squared_Hellinger_LT">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">Divergences_torch.</span></span><span class="sig-name descname"><span class="pre">squared_Hellinger_LT</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">discriminator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">disc_optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">discriminator_penalty</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_torch.html#squared_Hellinger_LT"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_torch.squared_Hellinger_LT" title="Link to this definition"></a></dt>
<dd><p>Squared Hellinger distance class based on the Legendre transform.
H(P||Q), x~P, y~Q.</p>
<dl class="py method">
<dt class="sig sig-object py" id="Divergences_torch.squared_Hellinger_LT.f_star">
<span class="sig-name descname"><span class="pre">f_star</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_torch.html#squared_Hellinger_LT.f_star"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_torch.squared_Hellinger_LT.f_star" title="Link to this definition"></a></dt>
<dd><p>Legendre transform of f(y) = (sqrt(y) - 1)^2.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Divergences_torch.squared_Hellinger_LT.final_layer_activation">
<span class="sig-name descname"><span class="pre">final_layer_activation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/Divergences_torch.html#squared_Hellinger_LT.final_layer_activation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#Divergences_torch.squared_Hellinger_LT.final_layer_activation" title="Link to this definition"></a></dt>
<dd><p>Applies the final layer activation for squared Hellinger distance.</p>
</dd></dl>

</dd></dl>

<dl class="py class" id="module-GAN_CIFAR10_jax">
<dt class="sig sig-object py" id="GAN_CIFAR10_jax.Discriminator">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">GAN_CIFAR10_jax.</span></span><span class="sig-name descname"><span class="pre">Discriminator</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">parent:</span> <span class="pre">~typing.Type[~flax.linen.module.Module]</span> <span class="pre">|</span> <span class="pre">~flax.core.scope.Scope</span> <span class="pre">|</span> <span class="pre">~typing.Type[~flax.linen.module._Sentinel]</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">&lt;flax.linen.module._Sentinel</span> <span class="pre">object&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/GAN_CIFAR10_jax.html#Discriminator"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#GAN_CIFAR10_jax.Discriminator" title="Link to this definition"></a></dt>
<dd><p>Discriminator class for an unconditional GAN model.
Applies several convolutional layers followed by LeakyReLU activations to classify the input.</p>
<dl class="py method">
<dt class="sig sig-object py" id="GAN_CIFAR10_jax.Discriminator.__call__">
<span class="sig-name descname"><span class="pre">__call__</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/GAN_CIFAR10_jax.html#Discriminator.__call__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#GAN_CIFAR10_jax.Discriminator.__call__" title="Link to this definition"></a></dt>
<dd><p>The forward pass through the network.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="GAN_CIFAR10_jax.Discriminator_cond">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">GAN_CIFAR10_jax.</span></span><span class="sig-name descname"><span class="pre">Discriminator_cond</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">parent:</span> <span class="pre">~typing.Type[~flax.linen.module.Module]</span> <span class="pre">|</span> <span class="pre">~flax.core.scope.Scope</span> <span class="pre">|</span> <span class="pre">~typing.Type[~flax.linen.module._Sentinel]</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">&lt;flax.linen.module._Sentinel</span> <span class="pre">object&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/GAN_CIFAR10_jax.html#Discriminator_cond"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#GAN_CIFAR10_jax.Discriminator_cond" title="Link to this definition"></a></dt>
<dd><p>Conditional Discriminator class for a GAN model.
Takes both images and labels as input and discriminates between real and fake images conditioned on the labels.</p>
<dl class="py method">
<dt class="sig sig-object py" id="GAN_CIFAR10_jax.Discriminator_cond.__call__">
<span class="sig-name descname"><span class="pre">__call__</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/GAN_CIFAR10_jax.html#Discriminator_cond.__call__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#GAN_CIFAR10_jax.Discriminator_cond.__call__" title="Link to this definition"></a></dt>
<dd><p>The forward pass through the network.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="GAN_CIFAR10_jax.Generator">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">GAN_CIFAR10_jax.</span></span><span class="sig-name descname"><span class="pre">Generator</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">parent:</span> <span class="pre">~typing.Type[~flax.linen.module.Module]</span> <span class="pre">|</span> <span class="pre">~flax.core.scope.Scope</span> <span class="pre">|</span> <span class="pre">~typing.Type[~flax.linen.module._Sentinel]</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">&lt;flax.linen.module._Sentinel</span> <span class="pre">object&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/GAN_CIFAR10_jax.html#Generator"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#GAN_CIFAR10_jax.Generator" title="Link to this definition"></a></dt>
<dd><p>Generator class for an unconditional GAN model.
Takes a latent code and generates images using deconvolutional layers.</p>
<dl class="py method">
<dt class="sig sig-object py" id="GAN_CIFAR10_jax.Generator.__call__">
<span class="sig-name descname"><span class="pre">__call__</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/GAN_CIFAR10_jax.html#Generator.__call__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#GAN_CIFAR10_jax.Generator.__call__" title="Link to this definition"></a></dt>
<dd><p>The forward pass through the network.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="GAN_CIFAR10_jax.Generator_cond">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">GAN_CIFAR10_jax.</span></span><span class="sig-name descname"><span class="pre">Generator_cond</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">parent:</span> <span class="pre">~typing.Type[~flax.linen.module.Module]</span> <span class="pre">|</span> <span class="pre">~flax.core.scope.Scope</span> <span class="pre">|</span> <span class="pre">~typing.Type[~flax.linen.module._Sentinel]</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">&lt;flax.linen.module._Sentinel</span> <span class="pre">object&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/GAN_CIFAR10_jax.html#Generator_cond"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#GAN_CIFAR10_jax.Generator_cond" title="Link to this definition"></a></dt>
<dd><p>Conditional Generator class for a GAN model.
Takes latent codes and labels to generate conditional images.</p>
<dl class="py method">
<dt class="sig sig-object py" id="GAN_CIFAR10_jax.Generator_cond.__call__">
<span class="sig-name descname"><span class="pre">__call__</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/GAN_CIFAR10_jax.html#Generator_cond.__call__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#GAN_CIFAR10_jax.Generator_cond.__call__" title="Link to this definition"></a></dt>
<dd><p>The forward pass through the network.</p>
</dd></dl>

</dd></dl>

<dl class="py class" id="module-GAN_CIFAR10_tf">
<dt class="sig sig-object py" id="GAN_CIFAR10_tf.Discriminator">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">GAN_CIFAR10_tf.</span></span><span class="sig-name descname"><span class="pre">Discriminator</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/GAN_CIFAR10_tf.html#Discriminator"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#GAN_CIFAR10_tf.Discriminator" title="Link to this definition"></a></dt>
<dd><p>Discriminator model, which evaluates whether inputs are real or fake.</p>
<dl class="py method">
<dt class="sig sig-object py" id="GAN_CIFAR10_tf.Discriminator.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/GAN_CIFAR10_tf.html#Discriminator.call"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#GAN_CIFAR10_tf.Discriminator.call" title="Link to this definition"></a></dt>
<dd><p>Passes input images through the discriminator network.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="GAN_CIFAR10_tf.Discriminator.build">
<span class="sig-name descname"><span class="pre">build</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/GAN_CIFAR10_tf.html#Discriminator.build"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#GAN_CIFAR10_tf.Discriminator.build" title="Link to this definition"></a></dt>
<dd><p>Build the discriminator.
:param input_shape: The shape of the input tensor.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id0">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/GAN_CIFAR10_tf.html#Discriminator.call"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id0" title="Link to this definition"></a></dt>
<dd><p>Forward pass of the discriminator.
:param inputs: Input images.
:type inputs: tf.Tensor
:param training: Whether the model is training.
:type training: bool</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Discriminator score for each image.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>tf.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="GAN_CIFAR10_tf.DiscriminatorBlock">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">GAN_CIFAR10_tf.</span></span><span class="sig-name descname"><span class="pre">DiscriminatorBlock</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/GAN_CIFAR10_tf.html#DiscriminatorBlock"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#GAN_CIFAR10_tf.DiscriminatorBlock" title="Link to this definition"></a></dt>
<dd><p>ResNet-style block for the discriminator model, with optional downsampling.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_chans</strong> (<em>int</em>) – Number of input channels.</p></li>
<li><p><strong>out_chans</strong> (<em>int</em>) – Number of output channels.</p></li>
<li><p><strong>downsample</strong> (<em>bool</em>) – Whether to apply 2x downsampling.</p></li>
<li><p><strong>first</strong> (<em>bool</em>) – Whether this is the first block in the discriminator.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="GAN_CIFAR10_tf.DiscriminatorBlock.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/GAN_CIFAR10_tf.html#DiscriminatorBlock.call"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#GAN_CIFAR10_tf.DiscriminatorBlock.call" title="Link to this definition"></a></dt>
<dd><p>Passes input through the discriminator block.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="GAN_CIFAR10_tf.DiscriminatorBlock.build">
<span class="sig-name descname"><span class="pre">build</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/GAN_CIFAR10_tf.html#DiscriminatorBlock.build"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#GAN_CIFAR10_tf.DiscriminatorBlock.build" title="Link to this definition"></a></dt>
<dd><p>Build the layer.
:param input_shape: The shape of the input tensor.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id1">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/GAN_CIFAR10_tf.html#DiscriminatorBlock.call"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id1" title="Link to this definition"></a></dt>
<dd><p>Forward pass of the discriminator block.
:param inputs: Input tensor.
:type inputs: tf.Tensor</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Output tensor after passing through the block.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>tf.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="GAN_CIFAR10_tf.Generator">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">GAN_CIFAR10_tf.</span></span><span class="sig-name descname"><span class="pre">Generator</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/GAN_CIFAR10_tf.html#Generator"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#GAN_CIFAR10_tf.Generator" title="Link to this definition"></a></dt>
<dd><p>Generator model that consists of a dense layer followed by multiple generator blocks.</p>
<dl class="py method">
<dt class="sig sig-object py" id="GAN_CIFAR10_tf.Generator.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/GAN_CIFAR10_tf.html#Generator.call"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#GAN_CIFAR10_tf.Generator.call" title="Link to this definition"></a></dt>
<dd><p>Passes input latent vectors through the generator network.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="GAN_CIFAR10_tf.Generator.build">
<span class="sig-name descname"><span class="pre">build</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/GAN_CIFAR10_tf.html#Generator.build"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#GAN_CIFAR10_tf.Generator.build" title="Link to this definition"></a></dt>
<dd><p>Build the generator.
:param input_shape: The shape of the input tensor.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id2">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">noise</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/GAN_CIFAR10_tf.html#Generator.call"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id2" title="Link to this definition"></a></dt>
<dd><p>Forward pass of the generator.
:param noise: Latent vectors.
:type noise: tf.Tensor
:param training: If the model is training.
:type training: bool</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Generated image tensor.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>tf.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="GAN_CIFAR10_tf.GeneratorBlock">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">GAN_CIFAR10_tf.</span></span><span class="sig-name descname"><span class="pre">GeneratorBlock</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/GAN_CIFAR10_tf.html#GeneratorBlock"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#GAN_CIFAR10_tf.GeneratorBlock" title="Link to this definition"></a></dt>
<dd><p>ResNet-style block for the generator model, with optional upsampling.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_chans</strong> (<em>int</em>) – Number of input channels.</p></li>
<li><p><strong>out_chans</strong> (<em>int</em>) – Number of output channels.</p></li>
<li><p><strong>upsample</strong> (<em>bool</em>) – Whether to apply 2x upsampling.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="GAN_CIFAR10_tf.GeneratorBlock.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/GAN_CIFAR10_tf.html#GeneratorBlock.call"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#GAN_CIFAR10_tf.GeneratorBlock.call" title="Link to this definition"></a></dt>
<dd><p>Passes input through the generator block.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="GAN_CIFAR10_tf.GeneratorBlock.build">
<span class="sig-name descname"><span class="pre">build</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/GAN_CIFAR10_tf.html#GeneratorBlock.build"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#GAN_CIFAR10_tf.GeneratorBlock.build" title="Link to this definition"></a></dt>
<dd><p>Build the layer.
:param input_shape: The shape of the input tensor.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id3">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/GAN_CIFAR10_tf.html#GeneratorBlock.call"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id3" title="Link to this definition"></a></dt>
<dd><p>Forward pass of the generator block.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>inputs</strong> (<em>tf.Tensor</em>) – Input tensor.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Output tensor after passing through the block.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tf.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="GAN_CIFAR10_tf.GeneratorBlock.compute_output_shape">
<span class="sig-name descname"><span class="pre">compute_output_shape</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/GAN_CIFAR10_tf.html#GeneratorBlock.compute_output_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#GAN_CIFAR10_tf.GeneratorBlock.compute_output_shape" title="Link to this definition"></a></dt>
<dd><p>Compute output shape of the block.
:param input_shape: The shape of the input tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tuple of the output shape.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="GAN_CIFAR10_tf.GeneratorBlock.from_config">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_config</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/GAN_CIFAR10_tf.html#GeneratorBlock.from_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#GAN_CIFAR10_tf.GeneratorBlock.from_config" title="Link to this definition"></a></dt>
<dd><p>Instantiate the block from a configuration.
:param config: Configuration dictionary.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>An instance of GeneratorBlock.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="#GAN_CIFAR10_tf.GeneratorBlock" title="GAN_CIFAR10_tf.GeneratorBlock">GeneratorBlock</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="GAN_CIFAR10_tf.GeneratorBlock.get_config">
<span class="sig-name descname"><span class="pre">get_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/GAN_CIFAR10_tf.html#GeneratorBlock.get_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#GAN_CIFAR10_tf.GeneratorBlock.get_config" title="Link to this definition"></a></dt>
<dd><p>Get the configuration of the block for serialization.
:returns: Configuration dictionary.
:rtype: dict</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="GAN_CIFAR10_tf.avg_pool2d">
<span class="sig-prename descclassname"><span class="pre">GAN_CIFAR10_tf.</span></span><span class="sig-name descname"><span class="pre">avg_pool2d</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/GAN_CIFAR10_tf.html#avg_pool2d"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#GAN_CIFAR10_tf.avg_pool2d" title="Link to this definition"></a></dt>
<dd><p>Implements a twice-differentiable 2x2 average pooling operation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>tf.Tensor</em>) – Input tensor of shape (batch_size, height, width, channels).</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Averaged pooled tensor.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tf.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py class" id="module-GAN_CIFAR10_torch">
<dt class="sig sig-object py" id="GAN_CIFAR10_torch.Discriminator">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">GAN_CIFAR10_torch.</span></span><span class="sig-name descname"><span class="pre">Discriminator</span></span><a class="reference internal" href="_modules/GAN_CIFAR10_torch.html#Discriminator"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#GAN_CIFAR10_torch.Discriminator" title="Link to this definition"></a></dt>
<dd><p>Discriminator (or critic) model for GAN.</p>
<dl class="py method">
<dt class="sig sig-object py" id="GAN_CIFAR10_torch.Discriminator.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/GAN_CIFAR10_torch.html#Discriminator.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#GAN_CIFAR10_torch.Discriminator.forward" title="Link to this definition"></a></dt>
<dd><p>Passes input images through the discriminator.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id4">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/GAN_CIFAR10_torch.html#Discriminator.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id4" title="Link to this definition"></a></dt>
<dd><p>Forward pass of the discriminator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>inputs</strong> (<em>torch.Tensor</em>) – Input image tensor.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Scalar score for each image.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="GAN_CIFAR10_torch.DiscriminatorBlock">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">GAN_CIFAR10_torch.</span></span><span class="sig-name descname"><span class="pre">DiscriminatorBlock</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_chans</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_chans</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">downsample</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">first</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/GAN_CIFAR10_torch.html#DiscriminatorBlock"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#GAN_CIFAR10_torch.DiscriminatorBlock" title="Link to this definition"></a></dt>
<dd><p>ResNet-style block for the discriminator model, with optional downsampling.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_chans</strong> (<em>int</em>) – Number of input channels.</p></li>
<li><p><strong>out_chans</strong> (<em>int</em>) – Number of output channels.</p></li>
<li><p><strong>downsample</strong> (<em>bool</em>) – Whether to apply 2x downsampling.</p></li>
<li><p><strong>first</strong> (<em>bool</em>) – Whether this is the first block in the discriminator.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="GAN_CIFAR10_torch.DiscriminatorBlock.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/GAN_CIFAR10_torch.html#DiscriminatorBlock.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#GAN_CIFAR10_torch.DiscriminatorBlock.forward" title="Link to this definition"></a></dt>
<dd><p>Passes input through the discriminator block.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id5">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/GAN_CIFAR10_torch.html#DiscriminatorBlock.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id5" title="Link to this definition"></a></dt>
<dd><p>Forward pass of the discriminator block.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>inputs</strong> (<em>torch.Tensor</em>) – Input tensor.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Output tensor after passing through the block.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="GAN_CIFAR10_torch.Discriminator_cond">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">GAN_CIFAR10_torch.</span></span><span class="sig-name descname"><span class="pre">Discriminator_cond</span></span><a class="reference internal" href="_modules/GAN_CIFAR10_torch.html#Discriminator_cond"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#GAN_CIFAR10_torch.Discriminator_cond" title="Link to this definition"></a></dt>
<dd><p>Conditional Discriminator (or critic) model for conditional GAN.</p>
<dl class="py method">
<dt class="sig sig-object py" id="GAN_CIFAR10_torch.Discriminator_cond.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/GAN_CIFAR10_torch.html#Discriminator_cond.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#GAN_CIFAR10_torch.Discriminator_cond.forward" title="Link to this definition"></a></dt>
<dd><p>Passes input images and labels through the discriminator.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id6">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/GAN_CIFAR10_torch.html#Discriminator_cond.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id6" title="Link to this definition"></a></dt>
<dd><p>Forward pass of the conditional discriminator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>torch.Tensor</em>) – Input image tensor.</p></li>
<li><p><strong>labels</strong> (<em>torch.Tensor</em>) – One-hot encoded labels.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Scalar score for each image.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="GAN_CIFAR10_torch.Generator">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">GAN_CIFAR10_torch.</span></span><span class="sig-name descname"><span class="pre">Generator</span></span><a class="reference internal" href="_modules/GAN_CIFAR10_torch.html#Generator"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#GAN_CIFAR10_torch.Generator" title="Link to this definition"></a></dt>
<dd><p>Generator model that consists of linear layers followed by multiple generator blocks.</p>
<dl class="py method">
<dt class="sig sig-object py" id="GAN_CIFAR10_torch.Generator.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/GAN_CIFAR10_torch.html#Generator.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#GAN_CIFAR10_torch.Generator.forward" title="Link to this definition"></a></dt>
<dd><p>Passes input latent vectors through the generator network.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id7">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/GAN_CIFAR10_torch.html#Generator.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id7" title="Link to this definition"></a></dt>
<dd><p>Forward pass of the generator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<em>torch.Tensor</em>) – Latent vectors.</p></li>
<li><p><strong>labels</strong> (<em>torch.Tensor</em>) – (Optional) Labels, if required.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Generated image tensor.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="GAN_CIFAR10_torch.GeneratorBlock">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">GAN_CIFAR10_torch.</span></span><span class="sig-name descname"><span class="pre">GeneratorBlock</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_chans</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_chans</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">upsample</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/GAN_CIFAR10_torch.html#GeneratorBlock"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#GAN_CIFAR10_torch.GeneratorBlock" title="Link to this definition"></a></dt>
<dd><p>ResNet-style block for the generator model, with optional upsampling.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_chans</strong> (<em>int</em>) – Number of input channels.</p></li>
<li><p><strong>out_chans</strong> (<em>int</em>) – Number of output channels.</p></li>
<li><p><strong>upsample</strong> (<em>bool</em>) – Whether to apply 2x upsampling.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="GAN_CIFAR10_torch.GeneratorBlock.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/GAN_CIFAR10_torch.html#GeneratorBlock.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#GAN_CIFAR10_torch.GeneratorBlock.forward" title="Link to this definition"></a></dt>
<dd><p>Passes input through the generator block.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id8">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/GAN_CIFAR10_torch.html#GeneratorBlock.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id8" title="Link to this definition"></a></dt>
<dd><p>Forward pass of the generator block.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>inputs</strong> (<em>torch.Tensor</em>) – Input tensor.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Output tensor after passing through the block.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="GAN_CIFAR10_torch.Generator_cond">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">GAN_CIFAR10_torch.</span></span><span class="sig-name descname"><span class="pre">Generator_cond</span></span><a class="reference internal" href="_modules/GAN_CIFAR10_torch.html#Generator_cond"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#GAN_CIFAR10_torch.Generator_cond" title="Link to this definition"></a></dt>
<dd><p>Conditional Generator model for conditional GAN.</p>
<dl class="py method">
<dt class="sig sig-object py" id="GAN_CIFAR10_torch.Generator_cond.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/GAN_CIFAR10_torch.html#Generator_cond.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#GAN_CIFAR10_torch.Generator_cond.forward" title="Link to this definition"></a></dt>
<dd><p>Passes input latent vectors and labels through the generator.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id9">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">z</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/GAN_CIFAR10_torch.html#Generator_cond.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id9" title="Link to this definition"></a></dt>
<dd><p>Forward pass of the conditional generator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>z</strong> (<em>torch.Tensor</em>) – Latent vectors.</p></li>
<li><p><strong>labels</strong> (<em>torch.Tensor</em>) – One-hot encoded labels.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Generated image tensor.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="GAN_CIFAR10_torch.avg_pool2d">
<span class="sig-prename descclassname"><span class="pre">GAN_CIFAR10_torch.</span></span><span class="sig-name descname"><span class="pre">avg_pool2d</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/GAN_CIFAR10_torch.html#avg_pool2d"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#GAN_CIFAR10_torch.avg_pool2d" title="Link to this definition"></a></dt>
<dd><p>Implements a twice-differentiable 2x2 average pooling operation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>torch.Tensor</em>) – Input tensor of shape (batch_size, channels, height, width).</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Averaged pooled tensor.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py class" id="module-GAN_MNIST_jax">
<dt class="sig sig-object py" id="GAN_MNIST_jax.Discriminator_MNIST_cond">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">GAN_MNIST_jax.</span></span><span class="sig-name descname"><span class="pre">Discriminator_MNIST_cond</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">parent:</span> <span class="pre">Union[Type[flax.linen.module.Module],</span> <span class="pre">flax.core.scope.Scope,</span> <span class="pre">Type[flax.linen.module._Sentinel],</span> <span class="pre">NoneType]</span> <span class="pre">=</span> <span class="pre">&lt;flax.linen.module._Sentinel</span> <span class="pre">object</span> <span class="pre">at</span> <span class="pre">0x7131f8d43fa0&gt;,</span> <span class="pre">name:</span> <span class="pre">Optional[str]</span> <span class="pre">=</span> <span class="pre">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/GAN_MNIST_jax.html#Discriminator_MNIST_cond"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#GAN_MNIST_jax.Discriminator_MNIST_cond" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="GAN_MNIST_jax.Generator_MNIST_cond">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">GAN_MNIST_jax.</span></span><span class="sig-name descname"><span class="pre">Generator_MNIST_cond</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">latent_dim:</span> <span class="pre">int</span> <span class="pre">=</span> <span class="pre">118,</span> <span class="pre">num_classes:</span> <span class="pre">int</span> <span class="pre">=</span> <span class="pre">10,</span> <span class="pre">parent:</span> <span class="pre">Union[Type[flax.linen.module.Module],</span> <span class="pre">flax.core.scope.Scope,</span> <span class="pre">Type[flax.linen.module._Sentinel],</span> <span class="pre">NoneType]</span> <span class="pre">=</span> <span class="pre">&lt;flax.linen.module._Sentinel</span> <span class="pre">object</span> <span class="pre">at</span> <span class="pre">0x7131f8d43fa0&gt;,</span> <span class="pre">name:</span> <span class="pre">Optional[str]</span> <span class="pre">=</span> <span class="pre">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/GAN_MNIST_jax.html#Generator_MNIST_cond"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#GAN_MNIST_jax.Generator_MNIST_cond" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function" id="module-GAN_MNIST_tf">
<dt class="sig sig-object py" id="GAN_MNIST_tf.Discriminator_MNIST_cond">
<span class="sig-prename descclassname"><span class="pre">GAN_MNIST_tf.</span></span><span class="sig-name descname"><span class="pre">Discriminator_MNIST_cond</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/GAN_MNIST_tf.html#Discriminator_MNIST_cond"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#GAN_MNIST_tf.Discriminator_MNIST_cond" title="Link to this definition"></a></dt>
<dd><p>Conditional Discriminator model for MNIST dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>A Keras model that takes as input an image and a one-hot encoded label and outputs a scalar value indicating real or fake.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>Model</p>
</dd>
</dl>
<dl class="simple">
<dt>Input:</dt><dd><p>x_input (Tensor): Input MNIST image of shape (batch_size, 28, 28).
z_input (Tensor): One-hot encoded label of shape (batch_size, 10).</p>
</dd>
<dt>Output:</dt><dd><p>Tensor: Discriminator output scalar for each image in the batch.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="GAN_MNIST_tf.Generator_MNIST_cond">
<span class="sig-prename descclassname"><span class="pre">GAN_MNIST_tf.</span></span><span class="sig-name descname"><span class="pre">Generator_MNIST_cond</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">latent_dim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">118</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/GAN_MNIST_tf.html#Generator_MNIST_cond"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#GAN_MNIST_tf.Generator_MNIST_cond" title="Link to this definition"></a></dt>
<dd><p>Conditional Generator model for MNIST dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>latent_dim</strong> (<em>int</em>) – Dimension of the latent input vector. Default is 118.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A Keras model that takes as input a latent vector and a one-hot encoded label and outputs a generated image.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Model</p>
</dd>
</dl>
<dl class="simple">
<dt>Input:</dt><dd><p>label (Tensor): One-hot encoded label of shape (batch_size, 10).
z (Tensor): Latent input vector of shape (batch_size, latent_dim).</p>
</dd>
<dt>Output:</dt><dd><p>Tensor: Generated image of shape (batch_size, 24, 24, 1).</p>
</dd>
</dl>
</dd></dl>

<dl class="py class" id="module-GAN_MNIST_torch">
<dt class="sig sig-object py" id="GAN_MNIST_torch.Discriminator_MNIST">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">GAN_MNIST_torch.</span></span><span class="sig-name descname"><span class="pre">Discriminator_MNIST</span></span><a class="reference internal" href="_modules/GAN_MNIST_torch.html#Discriminator_MNIST"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#GAN_MNIST_torch.Discriminator_MNIST" title="Link to this definition"></a></dt>
<dd><p>Unconditional Discriminator model for MNIST dataset.</p>
<dl class="py method">
<dt class="sig sig-object py" id="GAN_MNIST_torch.Discriminator_MNIST.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/GAN_MNIST_torch.html#Discriminator_MNIST.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#GAN_MNIST_torch.Discriminator_MNIST.forward" title="Link to this definition"></a></dt>
<dd><p>Classifies the input image as real or fake.</p>
</dd></dl>

<dl class="simple">
<dt>Input:</dt><dd><p>x (Tensor): Input MNIST image of shape (BATCH, 1, 28, 28).</p>
</dd>
<dt>Output:</dt><dd><p>Tensor: Discriminator output scalar for each image in the batch.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="id10">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/GAN_MNIST_torch.html#Discriminator_MNIST.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id10" title="Link to this definition"></a></dt>
<dd><p>Define the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="GAN_MNIST_torch.Discriminator_MNIST_cond">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">GAN_MNIST_torch.</span></span><span class="sig-name descname"><span class="pre">Discriminator_MNIST_cond</span></span><a class="reference internal" href="_modules/GAN_MNIST_torch.html#Discriminator_MNIST_cond"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#GAN_MNIST_torch.Discriminator_MNIST_cond" title="Link to this definition"></a></dt>
<dd><p>Conditional Discriminator model for MNIST dataset.</p>
<dl class="py method">
<dt class="sig sig-object py" id="GAN_MNIST_torch.Discriminator_MNIST_cond.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">z</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/GAN_MNIST_torch.html#Discriminator_MNIST_cond.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#GAN_MNIST_torch.Discriminator_MNIST_cond.forward" title="Link to this definition"></a></dt>
<dd><p>Classifies the input image and label as real or fake.</p>
</dd></dl>

<dl class="simple">
<dt>Input:</dt><dd><p>x (Tensor): Input MNIST image of shape (BATCH, 1, 28, 28).
z (Tensor): One-hot encoded label tensor of shape (BATCH, 10).</p>
</dd>
<dt>Output:</dt><dd><p>Tensor: Discriminator output scalar for each image in the batch.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="id11">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">z</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/GAN_MNIST_torch.html#Discriminator_MNIST_cond.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id11" title="Link to this definition"></a></dt>
<dd><p>Define the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="GAN_MNIST_torch.Generator_MNIST">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">GAN_MNIST_torch.</span></span><span class="sig-name descname"><span class="pre">Generator_MNIST</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">latent_dim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">118</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/GAN_MNIST_torch.html#Generator_MNIST"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#GAN_MNIST_torch.Generator_MNIST" title="Link to this definition"></a></dt>
<dd><p>Unconditional Generator model for MNIST dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>latent_dim</strong> (<em>int</em>) – Dimension of the latent input vector. Default is 118.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="GAN_MNIST_torch.Generator_MNIST.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">BATCH</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">16</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/GAN_MNIST_torch.html#Generator_MNIST.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#GAN_MNIST_torch.Generator_MNIST.forward" title="Link to this definition"></a></dt>
<dd><p>Generates an image based on a random noise vector.</p>
</dd></dl>

<dl class="simple">
<dt>Input:</dt><dd><p>BATCH (int): Batch size for random latent vector generation. Default is 16.</p>
</dd>
<dt>Output:</dt><dd><p>Tensor: Generated image of shape (BATCH, 1, 28, 28).</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="id12">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">BATCH</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">16</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/GAN_MNIST_torch.html#Generator_MNIST.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id12" title="Link to this definition"></a></dt>
<dd><p>Define the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="GAN_MNIST_torch.Generator_MNIST_cond">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">GAN_MNIST_torch.</span></span><span class="sig-name descname"><span class="pre">Generator_MNIST_cond</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">latent_dim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">118</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/GAN_MNIST_torch.html#Generator_MNIST_cond"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#GAN_MNIST_torch.Generator_MNIST_cond" title="Link to this definition"></a></dt>
<dd><p>Conditional Generator model for MNIST dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>latent_dim</strong> (<em>int</em>) – Dimension of the latent input vector. Default is 118.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="GAN_MNIST_torch.Generator_MNIST_cond.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">label</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">BATCH</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">16</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/GAN_MNIST_torch.html#Generator_MNIST_cond.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#GAN_MNIST_torch.Generator_MNIST_cond.forward" title="Link to this definition"></a></dt>
<dd><p>Generates an image conditioned on the input label and a random noise vector.</p>
</dd></dl>

<dl class="simple">
<dt>Input:</dt><dd><p>label (Tensor): One-hot encoded label tensor of shape (BATCH, 10).
BATCH (int): Batch size for random latent vector generation. Default is 16.</p>
</dd>
<dt>Output:</dt><dd><p>Tensor: Generated image of shape (BATCH, 1, 28, 28).</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="id13">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">label</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">BATCH</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">16</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/GAN_MNIST_torch.html#Generator_MNIST_cond.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id13" title="Link to this definition"></a></dt>
<dd><p>Define the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="py class" id="module-GAN_jax">
<dt class="sig sig-object py" id="GAN_jax.GAN">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">GAN_jax.</span></span><span class="sig-name descname"><span class="pre">GAN</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">divergence</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">generator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gen_optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">noise_source</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">disc_steps_per_gen_step</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reverse_order</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include_penalty_in_gen_loss</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cnn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/GAN_jax.html#GAN"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#GAN_jax.GAN" title="Link to this definition"></a></dt>
<dd><p>Class for training a GAN using one of the provided divergences
If reverse_order=False the GAN works to minimize min_theta D(P||g_theta(Z)) where P is the distribution to be leared, Z is the noise source and g_theta is the generator (with parameters theta).
If reverse_order=True the GAN works to minimize min_theta D(g_theta(Z)||P) where P is the distribution to be leared, Z is the noise source and g_theta is the generator (with parameters theta).</p>
<dl class="py method">
<dt class="sig sig-object py" id="GAN_jax.GAN.disc_train_step">
<span class="sig-name descname"><span class="pre">disc_train_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">z</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">disc_params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">disc_opt_state</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/GAN_jax.html#GAN.disc_train_step"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#GAN_jax.GAN.disc_train_step" title="Link to this definition"></a></dt>
<dd><p>discriminator’s parameters update</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="GAN_jax.GAN.estimate_loss">
<span class="sig-name descname"><span class="pre">estimate_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">z</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gen_params</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/GAN_jax.html#GAN.estimate_loss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#GAN_jax.GAN.estimate_loss" title="Link to this definition"></a></dt>
<dd><p>Estimating the loss</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="GAN_jax.GAN.gen_train_step">
<span class="sig-name descname"><span class="pre">gen_train_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">z</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gen_params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gen_opt_state</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/GAN_jax.html#GAN.gen_train_step"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#GAN_jax.GAN.gen_train_step" title="Link to this definition"></a></dt>
<dd><p>generator’s parameters update</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="GAN_jax.GAN.train">
<span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_P</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">disc_params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gen_params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">disc_opt_state</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gen_opt_state</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_frequency</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_gen_samples_to_save</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_loss_estimates</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/GAN_jax.html#GAN.train"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#GAN_jax.GAN.train" title="Link to this definition"></a></dt>
<dd><p>training function of our GAN</p>
</dd></dl>

</dd></dl>

<dl class="py class" id="module-GAN_tf">
<dt class="sig sig-object py" id="GAN_tf.GAN">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">GAN_tf.</span></span><span class="sig-name descname"><span class="pre">GAN</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">divergence</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">generator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gen_optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">noise_source</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">disc_steps_per_gen_step</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reverse_order</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include_penalty_in_gen_loss</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/GAN_tf.html#GAN"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#GAN_tf.GAN" title="Link to this definition"></a></dt>
<dd><p>Class for training a GAN using one of the provided divergences
If reverse_order=False the GAN works to minimize min_theta D(P||g_theta(Z)) where P is the distribution to be leared, Z is the noise source and g_theta is the generator (with parameters theta).
If reverse_order=True the GAN works to minimize min_theta D(g_theta(Z)||P) where P is the distribution to be leared, Z is the noise source and g_theta is the generator (with parameters theta).</p>
<dl class="py method">
<dt class="sig sig-object py" id="GAN_tf.GAN.disc_train_step">
<span class="sig-name descname"><span class="pre">disc_train_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">z</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/GAN_tf.html#GAN.disc_train_step"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#GAN_tf.GAN.disc_train_step" title="Link to this definition"></a></dt>
<dd><p>discriminator’s parameters update.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="GAN_tf.GAN.estimate_loss">
<span class="sig-name descname"><span class="pre">estimate_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">z</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/GAN_tf.html#GAN.estimate_loss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#GAN_tf.GAN.estimate_loss" title="Link to this definition"></a></dt>
<dd><p>Estimating the loss</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="GAN_tf.GAN.gen_train_step">
<span class="sig-name descname"><span class="pre">gen_train_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">z</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/GAN_tf.html#GAN.gen_train_step"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#GAN_tf.GAN.gen_train_step" title="Link to this definition"></a></dt>
<dd><p>generator’s parameters update.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="GAN_tf.GAN.train">
<span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_P</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_frequency</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_gen_samples_to_save</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_loss_estimates</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/GAN_tf.html#GAN.train"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#GAN_tf.GAN.train" title="Link to this definition"></a></dt>
<dd><p>training function of our GAN</p>
</dd></dl>

</dd></dl>

<dl class="py class" id="module-GAN_torch">
<dt class="sig sig-object py" id="GAN_torch.GAN">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">GAN_torch.</span></span><span class="sig-name descname"><span class="pre">GAN</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">divergence</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">generator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gen_optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">noise_source</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">disc_steps_per_gen_step</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reverse_order</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include_penalty_in_gen_loss</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/GAN_torch.html#GAN"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#GAN_torch.GAN" title="Link to this definition"></a></dt>
<dd><p>Class for training a GAN using one of the provided divergences
If reverse_order=False the GAN works to minimize min_theta D(P||g_theta(Z)) where P is the distribution to be leared, Z is the noise source and g_theta is the generator (with parameters theta).
If reverse_order=True the GAN works to minimize min_theta D(g_theta(Z)||P) where P is the distribution to be leared, Z is the noise source and g_theta is the generator (with parameters theta).</p>
<dl class="py method">
<dt class="sig sig-object py" id="GAN_torch.GAN.disc_train_step">
<span class="sig-name descname"><span class="pre">disc_train_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">z</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/GAN_torch.html#GAN.disc_train_step"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#GAN_torch.GAN.disc_train_step" title="Link to this definition"></a></dt>
<dd><p>discriminator’s parameters update</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="GAN_torch.GAN.estimate_loss">
<span class="sig-name descname"><span class="pre">estimate_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">z</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/GAN_torch.html#GAN.estimate_loss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#GAN_torch.GAN.estimate_loss" title="Link to this definition"></a></dt>
<dd><p>Estimating the loss</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="GAN_torch.GAN.gen_train_step">
<span class="sig-name descname"><span class="pre">gen_train_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">z</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/GAN_torch.html#GAN.gen_train_step"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#GAN_torch.GAN.gen_train_step" title="Link to this definition"></a></dt>
<dd><p>generator’s parameters update</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="GAN_torch.GAN.train">
<span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_P</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_frequency</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_gen_samples_to_save</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_loss_estimates</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/GAN_torch.html#GAN.train"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#GAN_torch.GAN.train" title="Link to this definition"></a></dt>
<dd><p>training function of our GAN</p>
</dd></dl>

</dd></dl>

<dl class="py class" id="module-model_jax">
<dt class="sig sig-object py" id="model_jax.Discriminator">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">model_jax.</span></span><span class="sig-name descname"><span class="pre">Discriminator</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_dim:</span> <span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">spec_norm:</span> <span class="pre">bool</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounded:</span> <span class="pre">bool</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layers_list:</span> <span class="pre">list</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">parent:</span> <span class="pre">~typing.Type[~flax.linen.module.Module]</span> <span class="pre">|</span> <span class="pre">~flax.core.scope.Scope</span> <span class="pre">|</span> <span class="pre">~typing.Type[~flax.linen.module._Sentinel]</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">&lt;flax.linen.module._Sentinel</span> <span class="pre">object&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/model_jax.html#Discriminator"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#model_jax.Discriminator" title="Link to this definition"></a></dt>
<dd><p>Discriminator Class responsible for initializing and processing the discriminator network.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_dim</strong> (<em>int</em>) – Input dimension size.</p></li>
<li><p><strong>spec_norm</strong> (<em>bool</em>) – Whether to apply spectral normalization to layers.</p></li>
<li><p><strong>bounded</strong> (<em>bool</em>) – Whether to apply a bounded activation function to the final output.</p></li>
<li><p><strong>layers_list</strong> (<em>list</em>) – List of integers where each integer specifies the number of units in each hidden layer.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Output after applying the discriminator network with an optional bounded activation.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>jax.numpy.DeviceArray</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="model_jax.Discriminator.bounded_activation">
<span class="sig-name descname"><span class="pre">bounded_activation</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/model_jax.html#Discriminator.bounded_activation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#model_jax.Discriminator.bounded_activation" title="Link to this definition"></a></dt>
<dd><p>Apply bounded activation using the tanh function to constrain outputs within [-M, M].</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>jax.numpy.DeviceArray</em>) – Input data.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Bounded output after applying tanh activation.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>jax.numpy.DeviceArray</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="model_jax.DiscriminatorMNIST">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">model_jax.</span></span><span class="sig-name descname"><span class="pre">DiscriminatorMNIST</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">parent:</span> <span class="pre">~typing.Type[~flax.linen.module.Module]</span> <span class="pre">|</span> <span class="pre">~flax.core.scope.Scope</span> <span class="pre">|</span> <span class="pre">~typing.Type[~flax.linen.module._Sentinel]</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">&lt;flax.linen.module._Sentinel</span> <span class="pre">object&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/model_jax.html#DiscriminatorMNIST"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#model_jax.DiscriminatorMNIST" title="Link to this definition"></a></dt>
<dd><p>Discriminator for the MNIST dataset responsible for classifying real vs fake images.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Output after applying the discriminator network.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>jax.numpy.DeviceArray</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="model_jax.Generator">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">model_jax.</span></span><span class="sig-name descname"><span class="pre">Generator</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X_dim:</span> <span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Z_dim:</span> <span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">spec_norm:</span> <span class="pre">bool</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layers_list:</span> <span class="pre">list</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">parent:</span> <span class="pre">~typing.Type[~flax.linen.module.Module]</span> <span class="pre">|</span> <span class="pre">~flax.core.scope.Scope</span> <span class="pre">|</span> <span class="pre">~typing.Type[~flax.linen.module._Sentinel]</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">&lt;flax.linen.module._Sentinel</span> <span class="pre">object&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/model_jax.html#Generator"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#model_jax.Generator" title="Link to this definition"></a></dt>
<dd><p>Generator Class responsible for initializing and processing the generator network.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X_dim</strong> (<em>int</em>) – Dimension of the output generated by the generator.</p></li>
<li><p><strong>Z_dim</strong> (<em>int</em>) – Dimension of the input latent space.</p></li>
<li><p><strong>spec_norm</strong> (<em>bool</em>) – Whether to apply spectral normalization to layers.</p></li>
<li><p><strong>layers_list</strong> (<em>list</em>) – List of integers where each integer specifies the number of units in each hidden layer.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Generated output after passing through the generator network.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>jax.numpy.DeviceArray</p>
</dd>
</dl>
</dd></dl>

<dl class="py class" id="module-model_tf">
<dt class="sig sig-object py" id="model_tf.Discriminator">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">model_tf.</span></span><span class="sig-name descname"><span class="pre">Discriminator</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/model_tf.html#Discriminator"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#model_tf.Discriminator" title="Link to this definition"></a></dt>
<dd><p>Discriminator class responsible for initializing and processing the discriminator network.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_dim</strong> (<em>int</em>) – Dimension of the input features.</p></li>
<li><p><strong>spec_norm</strong> (<em>bool</em>) – Whether to apply spectral normalization to the layers.</p></li>
<li><p><strong>bounded</strong> (<em>bool</em>) – Whether to apply bounded activation on the final output.</p></li>
<li><p><strong>layers_list</strong> (<em>list</em>) – List of integers specifying the number of units for each hidden layer.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="model_tf.Discriminator.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/model_tf.html#Discriminator.call"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#model_tf.Discriminator.call" title="Link to this definition"></a></dt>
<dd><p>Forward pass through the network.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="model_tf.Discriminator.bounded_activation">
<span class="sig-name descname"><span class="pre">bounded_activation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/model_tf.html#Discriminator.bounded_activation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#model_tf.Discriminator.bounded_activation" title="Link to this definition"></a></dt>
<dd><p>Activation function to apply bounded output using tanh.</p>
</dd></dl>

<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Output after processing through the discriminator network.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>tf.Tensor</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="id14">
<span class="sig-name descname"><span class="pre">bounded_activation</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/model_tf.html#Discriminator.bounded_activation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id14" title="Link to this definition"></a></dt>
<dd><p>Apply a bounded activation using the tanh function, constraining the output within [-M, M].</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>tf.Tensor</em>) – Input data.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Output after applying bounded activation.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tf.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id15">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/model_tf.html#Discriminator.call"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id15" title="Link to this definition"></a></dt>
<dd><p>Forward pass through the discriminator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>inputs</strong> (<em>tf.Tensor</em>) – Input data to the network.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Discriminator’s prediction after processing the inputs.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tf.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="model_tf.DiscriminatorMNIST">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">model_tf.</span></span><span class="sig-name descname"><span class="pre">DiscriminatorMNIST</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/model_tf.html#DiscriminatorMNIST"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#model_tf.DiscriminatorMNIST" title="Link to this definition"></a></dt>
<dd><p>Discriminator class for the MNIST dataset, responsible for classifying real vs fake images.</p>
<dl class="py method">
<dt class="sig sig-object py" id="model_tf.DiscriminatorMNIST.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/model_tf.html#DiscriminatorMNIST.call"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#model_tf.DiscriminatorMNIST.call" title="Link to this definition"></a></dt>
<dd><p>Forward pass through the network.</p>
</dd></dl>

<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Output after processing the input image through the discriminator network.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>tf.Tensor</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="id16">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/model_tf.html#DiscriminatorMNIST.call"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id16" title="Link to this definition"></a></dt>
<dd><p>Forward pass through the MNIST discriminator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>tf.Tensor</em>) – Input image data reshaped to (batch_size, 784).</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Output after processing through dense and normalization layers.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tf.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="model_tf.Generator">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">model_tf.</span></span><span class="sig-name descname"><span class="pre">Generator</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/model_tf.html#Generator"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#model_tf.Generator" title="Link to this definition"></a></dt>
<dd><p>Generator class responsible for initializing and processing the generator network.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X_dim</strong> (<em>int</em>) – Dimension of the output generated by the generator.</p></li>
<li><p><strong>Z_dim</strong> (<em>int</em>) – Dimension of the input latent space.</p></li>
<li><p><strong>spec_norm</strong> (<em>bool</em>) – Whether to apply spectral normalization to the layers.</p></li>
<li><p><strong>layers_list</strong> (<em>list</em>) – List of integers specifying the number of units for each hidden layer.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="model_tf.Generator.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/model_tf.html#Generator.call"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#model_tf.Generator.call" title="Link to this definition"></a></dt>
<dd><p>Forward pass through the network.</p>
</dd></dl>

<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Generated output after processing the latent input.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>tf.Tensor</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="id17">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/model_tf.html#Generator.call"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id17" title="Link to this definition"></a></dt>
<dd><p>Forward pass through the generator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>inputs</strong> (<em>tf.Tensor</em>) – Input latent vector.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Generated output.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tf.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class" id="module-model_torch">
<dt class="sig sig-object py" id="model_torch.BoundedActivation">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">model_torch.</span></span><span class="sig-name descname"><span class="pre">BoundedActivation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">M</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100.0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/model_torch.html#BoundedActivation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#model_torch.BoundedActivation" title="Link to this definition"></a></dt>
<dd><p>Bounded Activation Layer that applies a bounded activation function using tanh.</p>
<dl class="py method">
<dt class="sig sig-object py" id="model_torch.BoundedActivation.bounded_activation">
<span class="sig-name descname"><span class="pre">bounded_activation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#model_torch.BoundedActivation.bounded_activation" title="Link to this definition"></a></dt>
<dd><p>Apply the bounded activation to the input tensor.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="model_torch.BoundedActivation.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/model_torch.html#BoundedActivation.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#model_torch.BoundedActivation.forward" title="Link to this definition"></a></dt>
<dd><p>Forward pass to apply bounded activation.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id18">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/model_torch.html#BoundedActivation.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id18" title="Link to this definition"></a></dt>
<dd><p>Forward pass through the bounded activation layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input</strong> (<em>torch.Tensor</em>) – Input tensor.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Output after applying bounded activation.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="model_torch.Discriminator">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">model_torch.</span></span><span class="sig-name descname"><span class="pre">Discriminator</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">spec_norm</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounded</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layers_list</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'cuda'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/model_torch.html#Discriminator"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#model_torch.Discriminator" title="Link to this definition"></a></dt>
<dd><p>Discriminator Class that initializes and processes the discriminator network.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_dim</strong> (<em>int</em>) – Dimension of the input features.</p></li>
<li><p><strong>batch_size</strong> (<em>int</em>) – Batch size for processing.</p></li>
<li><p><strong>spec_norm</strong> (<em>bool</em>) – Whether to apply spectral normalization to the layers.</p></li>
<li><p><strong>bounded</strong> (<em>bool</em>) – Whether to apply bounded activation on the final output.</p></li>
<li><p><strong>layers_list</strong> (<em>list</em>) – List of integers specifying the number of units for each hidden layer.</p></li>
<li><p><strong>device</strong> (<em>str</em>) – Device to run the model on (‘cpu’ or ‘cuda’).</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="model_torch.Discriminator.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/model_torch.html#Discriminator.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#model_torch.Discriminator.forward" title="Link to this definition"></a></dt>
<dd><p>Forward pass through the network.</p>
</dd></dl>

<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Output after processing through the discriminator network.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>torch.Tensor</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="id19">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/model_torch.html#Discriminator.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id19" title="Link to this definition"></a></dt>
<dd><p>Forward pass through the discriminator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>inputs</strong> (<em>torch.Tensor</em>) – Input data to the network.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Discriminator’s prediction after processing the inputs.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="model_torch.Discriminator_MNIST">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">model_torch.</span></span><span class="sig-name descname"><span class="pre">Discriminator_MNIST</span></span><a class="reference internal" href="_modules/model_torch.html#Discriminator_MNIST"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#model_torch.Discriminator_MNIST" title="Link to this definition"></a></dt>
<dd><p>Discriminator Class for MNIST that processes the input and classifies real vs fake images.</p>
<dl class="py method">
<dt class="sig sig-object py" id="model_torch.Discriminator_MNIST.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/model_torch.html#Discriminator_MNIST.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#model_torch.Discriminator_MNIST.forward" title="Link to this definition"></a></dt>
<dd><p>Forward pass through the network.</p>
</dd></dl>

<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Output after processing the input image through the discriminator network.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>torch.Tensor</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="id20">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/model_torch.html#Discriminator_MNIST.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id20" title="Link to this definition"></a></dt>
<dd><p>Forward pass through the MNIST discriminator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>torch.Tensor</em>) – Input image data reshaped to (batch_size, 784).</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Output after processing through dense and normalization layers.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="model_torch.Generator">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">model_torch.</span></span><span class="sig-name descname"><span class="pre">Generator</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Z_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">spec_norm</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layers_list</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'cuda'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/model_torch.html#Generator"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#model_torch.Generator" title="Link to this definition"></a></dt>
<dd><p>Generator Class that initializes and processes the generator network.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X_dim</strong> (<em>int</em>) – Dimension of the output generated by the generator.</p></li>
<li><p><strong>Z_dim</strong> (<em>int</em>) – Dimension of the input latent space.</p></li>
<li><p><strong>batch_size</strong> (<em>int</em>) – Batch size for processing.</p></li>
<li><p><strong>spec_norm</strong> (<em>bool</em>) – Whether to apply spectral normalization to the layers.</p></li>
<li><p><strong>layers_list</strong> (<em>list</em>) – List of integers specifying the number of units for each hidden layer.</p></li>
<li><p><strong>device</strong> (<em>str</em>) – Device to run the model on (‘cpu’ or ‘cuda’).</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="model_torch.Generator.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/model_torch.html#Generator.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#model_torch.Generator.forward" title="Link to this definition"></a></dt>
<dd><p>Forward pass through the network.</p>
</dd></dl>

<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Generated output after processing the latent input.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>torch.Tensor</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="id21">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/model_torch.html#Generator.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id21" title="Link to this definition"></a></dt>
<dd><p>Forward pass through the generator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>inputs</strong> (<em>torch.Tensor</em>) – Input latent vector.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Generated output.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="indices-and-tables">
<h1>Indices and tables<a class="headerlink" href="#indices-and-tables" title="Link to this heading"></a></h1>
<ul class="simple">
<li><p><a class="reference internal" href="genindex.html"><span class="std std-ref">Index</span></a></p></li>
<li><p><a class="reference internal" href="py-modindex.html"><span class="std std-ref">Module Index</span></a></p></li>
<li><p><a class="reference internal" href="search.html"><span class="std std-ref">Search Page</span></a></p></li>
</ul>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="modules.html" class="btn btn-neutral float-right" title="models" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, Alexandros Angelakis.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>